{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Download dataset"
      ],
      "metadata": {
        "id": "y2KdmK-uaq_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "6VpY83kRZ1Jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7gpm2C5ZJIx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import csv\n",
        "import tarfile\n",
        "import urllib.request\n",
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "tarball_url = \"http://download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "dirnames = [\"daisy\", \"dandelion\", \"roses\", \"sunflowers\", \"tulips\"]\n",
        "data_root = 'data'\n",
        "filename = tarball_url.split('/')[-1]\n",
        "filepath = os.path.join(data_root, filename)\n",
        "\n",
        "filepath, _ = urllib.request.urlretrieve(tarball_url, filepath)\n",
        "tarfile.open(filepath, \"r:gz\").extractall(data_root)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create .csv files containing image file names to be used inside your dataset class since it would be expensive to load ALL training images into memory so you may want to load only the images for each mini-batch."
      ],
      "metadata": {
        "id": "5flipQZAZSdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO DO: Create your own Dataset class definition and use DataLoader with it. Inside your dataset class, __getitem__() will use the stored file names with given input index in .csv file to load that image into memory."
      ],
      "metadata": {
        "id": "o8gCAe-qFhca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = os.path.join(data_root, \"flower\")\n",
        "\n",
        "if not os.path.exists(os.path.join(data_dir, \"train\")):\n",
        "    os.makedirs(os.path.join(data_dir, \"train\"))\n",
        "if not os.path.exists(os.path.join(data_dir, \"test\")):\n",
        "    os.makedirs(os.path.join(data_dir, \"test\"))\n",
        "\n",
        "print(\"[!] Converting images...\")\n",
        "# manage data with csv files\n",
        "train_f = open(os.path.join(data_dir, \"train.csv\"), \"w\")\n",
        "test_f = open(os.path.join(data_dir, \"test.csv\"), \"w\")\n",
        "train_writer, test_writer = csv.writer(train_f), csv.writer(test_f)\n",
        "\n",
        "for dirname in dirnames:\n",
        "    paths = glob.glob(os.path.join(\n",
        "        data_root, \"flower_photos\", dirname, \"*.jpg\"))\n",
        "\n",
        "    num_test = int(len(paths) * 0.2)\n",
        "\n",
        "    if not os.path.exists(os.path.join(data_dir, \"train\", dirname)):\n",
        "        os.makedirs(os.path.join(data_dir, \"train\", dirname))\n",
        "    if not os.path.exists(os.path.join(data_dir, \"test\", dirname)):\n",
        "        os.makedirs(os.path.join(data_dir, \"test\", dirname))\n",
        "\n",
        "    # prepare a training data\n",
        "    for path in paths[:-num_test]:\n",
        "        new_path = os.path.join(data_dir, \"train\",\n",
        "                                dirname, path.split(\"/\")[-1])\n",
        "\n",
        "        im = imageio.imread(path)\n",
        "        imageio.imsave(new_path, im)\n",
        "        train_writer.writerow([new_path, dirname])\n",
        "\n",
        "    # prepare a test data\n",
        "    for path in paths[-num_test:]:\n",
        "        new_path = os.path.join(data_dir, \"test\",\n",
        "                                dirname, path.split(\"/\")[-1])\n",
        "\n",
        "        im = imageio.imread(path)\n",
        "        imageio.imsave(new_path, im)\n",
        "        test_writer.writerow([new_path, dirname])\n",
        "\n",
        "train_f.close()\n",
        "test_f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uqzXtKRat4P",
        "outputId": "5a3782d8-a680-43b2-e070-f258e12b3812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[!] Converting images...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data\n",
        "from PIL import Image\n",
        "\n",
        "def default_loader(path):\n",
        "    return Image.open(path).convert('RGB')\n",
        "\n",
        "class myImageFloder(data.Dataset):\n",
        "    def __init__(self, root, label, transform = None, target_transform=None, loader=default_loader):\n",
        "\n",
        "        fn = np.loadtxt(label, delimiter=',', dtype='str')\n",
        "        '''edited'''\n",
        "        imgs = []\n",
        "\n",
        "        testlabel = fn[:, 1]\n",
        "        testimg = fn[:, 0]\n",
        "        count = 0\n",
        "        for name in testimg:\n",
        "            imgs.append((name,testlabel[count]))\n",
        "            count=count+1\n",
        "\n",
        "        self.root = root\n",
        "        self.imgs = fn\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.loader = loader\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename, label = self.imgs[index]\n",
        "        img = self.loader(filename)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, label, filename  # todo: for testing visualization, it needs filename\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def getName(self):\n",
        "        return self.classes"
      ],
      "metadata": {
        "id": "lx49yZP3eoWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "import torch.utils\n",
        "\n",
        "mytransform = transforms.Compose([\n",
        "\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),            # mmb\n",
        "    ]\n",
        ")\n",
        "\n",
        "data_set = myImageFloder(\n",
        "    root=\"data/flower/train\",\n",
        "    label=\"data/flower/train.csv\",\n",
        "    transform=mytransform,\n",
        "\n",
        ")\n",
        "data_set_test = myImageFloder(\n",
        "    root=\"data/flower/test\",\n",
        "    label=\"data/flower/test.csv\",\n",
        "    transform=mytransform,\n",
        "\n",
        ")\n",
        "imgLoader = torch.utils.data.DataLoader(\n",
        "    data_set,\n",
        "    batch_size=500, shuffle=True, num_workers=0\n",
        ")\n",
        "imgLoader_test = torch.utils.data.DataLoader(\n",
        "    data_set,\n",
        "    batch_size=500, shuffle=True, num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "yvmOqyNue1GE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5322e5dc-1021-40c5-a58e-b9220f44f63a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['data/flower/train/daisy/5054771689_00dd40b971_n.jpg'\n",
            " 'data/flower/train/daisy/2713919471_301fcc941f.jpg'\n",
            " 'data/flower/train/daisy/5809489674_5659b3ae5d_n.jpg' ...\n",
            " 'data/flower/train/tulips/13531007054_c88deaf302_n.jpg'\n",
            " 'data/flower/train/tulips/14025589299_eac64c51af_m.jpg'\n",
            " 'data/flower/train/tulips/130685040_3c2fcec63e_n.jpg']\n",
            "['data/flower/test/daisy/506018088_4f7a15a7c5_n.jpg'\n",
            " 'data/flower/test/daisy/294451721_5106537b34.jpg'\n",
            " 'data/flower/test/daisy/6776075110_1ea7a09dd4_n.jpg'\n",
            " 'data/flower/test/daisy/705422469_ffa28c566d.jpg'\n",
            " 'data/flower/test/daisy/4757448834_a29a9538c9_n.jpg'\n",
            " 'data/flower/test/daisy/6910811638_aa6f17df23.jpg'\n",
            " 'data/flower/test/daisy/8008258043_5457dd254b_n.jpg'\n",
            " 'data/flower/test/daisy/162362896_99c7d851c8_n.jpg'\n",
            " 'data/flower/test/daisy/10437754174_22ec990b77_m.jpg'\n",
            " 'data/flower/test/daisy/3483303007_42e3f90da7.jpg'\n",
            " 'data/flower/test/daisy/8694909523_3ca25d449d_n.jpg'\n",
            " 'data/flower/test/daisy/3713290261_8a66de23ab.jpg'\n",
            " 'data/flower/test/daisy/2351206867_084e57bd97.jpg'\n",
            " 'data/flower/test/daisy/14221848160_7f0a37c395.jpg'\n",
            " 'data/flower/test/daisy/5794839_200acd910c_n.jpg'\n",
            " 'data/flower/test/daisy/19834392829_7d697871f6.jpg'\n",
            " 'data/flower/test/daisy/2473825306_62fd5f8785_n.jpg'\n",
            " 'data/flower/test/daisy/5811226952_4650ed70ae_n.jpg'\n",
            " 'data/flower/test/daisy/19544831049_0d738d4872_m.jpg'\n",
            " 'data/flower/test/daisy/7335886184_d06a83f640.jpg'\n",
            " 'data/flower/test/daisy/2619413565_61a6cd3ac9_m.jpg'\n",
            " 'data/flower/test/daisy/2077865117_9ed85191ae_n.jpg'\n",
            " 'data/flower/test/daisy/14921511479_7b0a647795.jpg'\n",
            " 'data/flower/test/daisy/5973491805_556bba93cc.jpg'\n",
            " 'data/flower/test/daisy/4668543441_79040ca329_n.jpg'\n",
            " 'data/flower/test/daisy/21626652132_97e1318bb8_m.jpg'\n",
            " 'data/flower/test/daisy/5885826924_38fdc6bcaa_n.jpg'\n",
            " 'data/flower/test/daisy/4413849849_b8d2f3bcf1_n.jpg'\n",
            " 'data/flower/test/daisy/5434914569_e9b982fde0_n.jpg'\n",
            " 'data/flower/test/daisy/6884975451_c74f445d69_m.jpg'\n",
            " 'data/flower/test/daisy/23095658544_7226386954_n.jpg'\n",
            " 'data/flower/test/daisy/520752848_4b87fb91a4.jpg'\n",
            " 'data/flower/test/daisy/2509545845_99e79cb8a2_n.jpg'\n",
            " 'data/flower/test/daisy/3475870145_685a19116d.jpg'\n",
            " 'data/flower/test/daisy/8071646795_2fdc89ab7a_n.jpg'\n",
            " 'data/flower/test/daisy/5602738326_97121e007d_n.jpg'\n",
            " 'data/flower/test/daisy/2621723097_736febb4a4_n.jpg'\n",
            " 'data/flower/test/daisy/9310226774_d1b8f5d9c9.jpg'\n",
            " 'data/flower/test/daisy/153210866_03cc9f2f36.jpg'\n",
            " 'data/flower/test/daisy/3639009391_0f910681b7.jpg'\n",
            " 'data/flower/test/daisy/20773528301_008fcbc5a1_n.jpg'\n",
            " 'data/flower/test/daisy/173350276_02817aa8d5.jpg'\n",
            " 'data/flower/test/daisy/4276898893_609d11db8b.jpg'\n",
            " 'data/flower/test/daisy/2045022175_ad087f5f60_n.jpg'\n",
            " 'data/flower/test/daisy/15207766_fc2f1d692c_n.jpg'\n",
            " 'data/flower/test/daisy/4890424315_6a59696357_n.jpg'\n",
            " 'data/flower/test/daisy/4613992315_143ccc2a10_m.jpg'\n",
            " 'data/flower/test/daisy/4144275653_7c02d47d9b.jpg'\n",
            " 'data/flower/test/daisy/3611577717_f3a7a8c416_n.jpg'\n",
            " 'data/flower/test/daisy/14866200659_6462c723cb_m.jpg'\n",
            " 'data/flower/test/daisy/20182559506_40a112f762.jpg'\n",
            " 'data/flower/test/daisy/2349640101_212c275aa7.jpg'\n",
            " 'data/flower/test/daisy/3506866918_61dd5fc53b_n.jpg'\n",
            " 'data/flower/test/daisy/3900172983_9312fdf39c_n.jpg'\n",
            " 'data/flower/test/daisy/14350958832_29bdd3a254.jpg'\n",
            " 'data/flower/test/daisy/5874818796_3efbb8769d.jpg'\n",
            " 'data/flower/test/daisy/5110105726_53eb7a93be_m.jpg'\n",
            " 'data/flower/test/daisy/435283392_72e4c5b5d6_m.jpg'\n",
            " 'data/flower/test/daisy/5435521200_92029bbe2b_n.jpg'\n",
            " 'data/flower/test/daisy/11642632_1e7627a2cc.jpg'\n",
            " 'data/flower/test/daisy/3699235066_fc09a02dfe_m.jpg'\n",
            " 'data/flower/test/daisy/175106495_53ebdef092_n.jpg'\n",
            " 'data/flower/test/daisy/754248840_95092de274.jpg'\n",
            " 'data/flower/test/daisy/7133935763_82b17c8e1b_n.jpg'\n",
            " 'data/flower/test/daisy/16025261368_911703a536_n.jpg'\n",
            " 'data/flower/test/daisy/5714327423_50af0cffe9.jpg'\n",
            " 'data/flower/test/daisy/4540555191_3254dc4608_n.jpg'\n",
            " 'data/flower/test/daisy/18203367608_07a04e98a4_n.jpg'\n",
            " 'data/flower/test/daisy/506348009_9ecff8b6ef.jpg'\n",
            " 'data/flower/test/daisy/14402451388_56545a374a_n.jpg'\n",
            " 'data/flower/test/daisy/5435513198_90ce39f1aa_n.jpg'\n",
            " 'data/flower/test/daisy/176375506_201859bb92_m.jpg'\n",
            " 'data/flower/test/daisy/7749368884_1fc58c67ff_n.jpg'\n",
            " 'data/flower/test/daisy/8983779970_9d3a6a3bf2_n.jpg'\n",
            " 'data/flower/test/daisy/105806915_a9c13e2106_n.jpg'\n",
            " 'data/flower/test/daisy/14707111433_cce08ee007.jpg'\n",
            " 'data/flower/test/daisy/5795159787_ebb51a5e75.jpg'\n",
            " 'data/flower/test/daisy/3588872598_e0f9a1d2a1_m.jpg'\n",
            " 'data/flower/test/daisy/10770585085_4742b9dac3_n.jpg'\n",
            " 'data/flower/test/daisy/3533954656_79156c8473.jpg'\n",
            " 'data/flower/test/daisy/3491933306_43cfe2cfbe.jpg'\n",
            " 'data/flower/test/daisy/3326037909_b5ae370722_n.jpg'\n",
            " 'data/flower/test/daisy/3025866885_22fb0b61c6_n.jpg'\n",
            " 'data/flower/test/daisy/16819071290_471d99e166_m.jpg'\n",
            " 'data/flower/test/daisy/3627678863_557552c879_m.jpg'\n",
            " 'data/flower/test/daisy/19178753159_a471bf4b6b.jpg'\n",
            " 'data/flower/test/daisy/5869147563_66fb88119d.jpg'\n",
            " 'data/flower/test/daisy/16360180712_b72695928c_n.jpg'\n",
            " 'data/flower/test/daisy/1286274236_1d7ac84efb_n.jpg'\n",
            " 'data/flower/test/daisy/163978992_8128b49d3e_n.jpg'\n",
            " 'data/flower/test/daisy/4511693548_20f9bd2b9c_m.jpg'\n",
            " 'data/flower/test/daisy/20289938802_e16fa9f23d.jpg'\n",
            " 'data/flower/test/daisy/25360380_1a881a5648.jpg'\n",
            " 'data/flower/test/daisy/3310644753_5607eb96a4_m.jpg'\n",
            " 'data/flower/test/daisy/5876455546_32049e5585.jpg'\n",
            " 'data/flower/test/daisy/144076848_57e1d662e3_m.jpg'\n",
            " 'data/flower/test/daisy/14332947164_9b13513c71_m.jpg'\n",
            " 'data/flower/test/daisy/6054952060_c88612f3c5_n.jpg'\n",
            " 'data/flower/test/daisy/3695826945_9f374e8a00_m.jpg'\n",
            " 'data/flower/test/daisy/813445367_187ecf080a_n.jpg'\n",
            " 'data/flower/test/daisy/6136947177_47ff445eb4_n.jpg'\n",
            " 'data/flower/test/daisy/253426762_9793d43fcd.jpg'\n",
            " 'data/flower/test/daisy/3474942718_c418dae6f1.jpg'\n",
            " 'data/flower/test/daisy/4666648087_b10f376f19.jpg'\n",
            " 'data/flower/test/daisy/20948886919_cac7844f34_n.jpg'\n",
            " 'data/flower/test/daisy/3963330924_6c6a3fa7be_n.jpg'\n",
            " 'data/flower/test/daisy/8616684075_71923bb771_n.jpg'\n",
            " 'data/flower/test/daisy/6864242336_0d12713fe5_n.jpg'\n",
            " 'data/flower/test/daisy/16833748795_b681b2839f_n.jpg'\n",
            " 'data/flower/test/daisy/14621687774_ec52811acd_n.jpg'\n",
            " 'data/flower/test/daisy/3456403987_5bd5fa6ece_n.jpg'\n",
            " 'data/flower/test/daisy/14147016029_8d3cf2414e.jpg'\n",
            " 'data/flower/test/daisy/5773652803_574b51414f_n.jpg'\n",
            " 'data/flower/test/daisy/18635898912_eb8e058ef0.jpg'\n",
            " 'data/flower/test/daisy/16020253176_60f2a6a5ca_n.jpg'\n",
            " 'data/flower/test/daisy/10994032453_ac7f8d9e2e.jpg'\n",
            " 'data/flower/test/daisy/4646886118_b5c5ceaf6d_n.jpg'\n",
            " 'data/flower/test/daisy/5944315415_2be8abeb2f_m.jpg'\n",
            " 'data/flower/test/daisy/11834945233_a53b7a92ac_m.jpg'\n",
            " 'data/flower/test/daisy/144099102_bf63a41e4f_n.jpg'\n",
            " 'data/flower/test/daisy/14674743211_f68b13f6d9.jpg'\n",
            " 'data/flower/test/daisy/18679421522_3be9879e32.jpg'\n",
            " 'data/flower/test/daisy/9204730092_a7f2182347.jpg'\n",
            " 'data/flower/test/daisy/14087947408_9779257411_n.jpg'\n",
            " 'data/flower/test/daisy/2607132536_d95198e619_n.jpg'\n",
            " 'data/flower/test/daisy/9175280426_40ecc395b8_m.jpg'\n",
            " 'data/flower/test/dandelion/510874382_f7e3435043.jpg'\n",
            " 'data/flower/test/dandelion/3469112805_6cc8640236.jpg'\n",
            " 'data/flower/test/dandelion/8980145452_efbd6e3b04.jpg'\n",
            " 'data/flower/test/dandelion/2625836599_03e192266f.jpg'\n",
            " 'data/flower/test/dandelion/5110103388_78dc02558e_n.jpg'\n",
            " 'data/flower/test/dandelion/486234138_688e01aa9b_n.jpg'\n",
            " 'data/flower/test/dandelion/4226758402_a1b75ce3ac_n.jpg'\n",
            " 'data/flower/test/dandelion/2444241718_3ca53ce921.jpg'\n",
            " 'data/flower/test/dandelion/9262004825_710346cde9_n.jpg'\n",
            " 'data/flower/test/dandelion/4645101643_9c9d9df13e.jpg'\n",
            " 'data/flower/test/dandelion/14292205986_da230467ef.jpg'\n",
            " 'data/flower/test/dandelion/2512148749_261fa9d156.jpg'\n",
            " 'data/flower/test/dandelion/13887031789_97437f246b.jpg'\n",
            " 'data/flower/test/dandelion/9759608055_9ab623d193.jpg'\n",
            " 'data/flower/test/dandelion/5607256228_2294c201b3.jpg'\n",
            " 'data/flower/test/dandelion/2478018280_1be353ca8c_m.jpg'\n",
            " 'data/flower/test/dandelion/3844111216_742ea491a0.jpg'\n",
            " 'data/flower/test/dandelion/18342918441_b1bb69a2fd_n.jpg'\n",
            " 'data/flower/test/dandelion/15268682367_5a4512b29f_m.jpg'\n",
            " 'data/flower/test/dandelion/8701999625_8d83138124.jpg'\n",
            " 'data/flower/test/dandelion/2502610598_b9f1b55ebd_n.jpg'\n",
            " 'data/flower/test/dandelion/5129135346_3fa8e804d8_n.jpg'\n",
            " 'data/flower/test/dandelion/4573886524_5161482ca7_n.jpg'\n",
            " 'data/flower/test/dandelion/4557781241_0060cbe723_n.jpg'\n",
            " 'data/flower/test/dandelion/2481428401_bed64dd043.jpg'\n",
            " 'data/flower/test/dandelion/6918170172_3215766bf4_m.jpg'\n",
            " 'data/flower/test/dandelion/7808545612_546cfca610_m.jpg'\n",
            " 'data/flower/test/dandelion/8223949_2928d3f6f6_n.jpg'\n",
            " 'data/flower/test/dandelion/8842482175_92a14b4934_m.jpg'\n",
            " 'data/flower/test/dandelion/19004688463_12a8423109.jpg'\n",
            " 'data/flower/test/dandelion/3454102259_957ecd0a9b.jpg'\n",
            " 'data/flower/test/dandelion/7040710179_7f86a17a3c_n.jpg'\n",
            " 'data/flower/test/dandelion/3475811950_0fb89845f5_n.jpg'\n",
            " 'data/flower/test/dandelion/17135145776_4c2ec21b05_m.jpg'\n",
            " 'data/flower/test/dandelion/7164500544_332b75aa3b.jpg'\n",
            " 'data/flower/test/dandelion/15297244181_011883a631_m.jpg'\n",
            " 'data/flower/test/dandelion/8989067485_aab399460b_n.jpg'\n",
            " 'data/flower/test/dandelion/7197581386_8a51f1bb12_n.jpg'\n",
            " 'data/flower/test/dandelion/5644234724_cb0917ee33_m.jpg'\n",
            " 'data/flower/test/dandelion/5749815755_12f9214649_n.jpg'\n",
            " 'data/flower/test/dandelion/14200639491_2a4611916d_n.jpg'\n",
            " 'data/flower/test/dandelion/17388697431_0d84c427d1_n.jpg'\n",
            " 'data/flower/test/dandelion/3465599902_14729e2b1b_n.jpg'\n",
            " 'data/flower/test/dandelion/19602790836_912d38aaa8.jpg'\n",
            " 'data/flower/test/dandelion/3530500952_9f94fb8b9c_m.jpg'\n",
            " 'data/flower/test/dandelion/142813254_20a7fd5fb6_n.jpg'\n",
            " 'data/flower/test/dandelion/5110102140_787d325757_n.jpg'\n",
            " 'data/flower/test/dandelion/145173479_7d04346c20.jpg'\n",
            " 'data/flower/test/dandelion/6012046444_fd80afb63a_n.jpg'\n",
            " 'data/flower/test/dandelion/15987457_49dc11bf4b.jpg'\n",
            " 'data/flower/test/dandelion/14185089716_2a48298d17.jpg'\n",
            " 'data/flower/test/dandelion/4632235020_d00ce1e497.jpg'\n",
            " 'data/flower/test/dandelion/5416388641_c66d52d2ff_m.jpg'\n",
            " 'data/flower/test/dandelion/2076141453_c63801962a_m.jpg'\n",
            " 'data/flower/test/dandelion/2698102820_f15445a3f7.jpg'\n",
            " 'data/flower/test/dandelion/13807932364_673b7f1c1c_n.jpg'\n",
            " 'data/flower/test/dandelion/146023167_f905574d97_m.jpg'\n",
            " 'data/flower/test/dandelion/19443726008_8c9c68efa7_m.jpg'\n",
            " 'data/flower/test/dandelion/3562861685_8b8d747b4d.jpg'\n",
            " 'data/flower/test/dandelion/1193386857_3ae53574f2_m.jpg'\n",
            " 'data/flower/test/dandelion/20165867412_fc45d31698_m.jpg'\n",
            " 'data/flower/test/dandelion/61242541_a04395e6bc.jpg'\n",
            " 'data/flower/test/dandelion/7465850028_cdfaae235a_n.jpg'\n",
            " 'data/flower/test/dandelion/17020815734_81e8db8008_m.jpg'\n",
            " 'data/flower/test/dandelion/4556178143_e0d32c0a86_n.jpg'\n",
            " 'data/flower/test/dandelion/18304194360_2a4a0be631_m.jpg'\n",
            " 'data/flower/test/dandelion/9965757055_ff01b5ee6f_n.jpg'\n",
            " 'data/flower/test/dandelion/2462476884_58c617b26a.jpg'\n",
            " 'data/flower/test/dandelion/3496258301_ca5f168306.jpg'\n",
            " 'data/flower/test/dandelion/18271576032_d7e2296de4_n.jpg'\n",
            " 'data/flower/test/dandelion/8978962053_0727b41d26.jpg'\n",
            " 'data/flower/test/dandelion/10779476016_9130714dc0.jpg'\n",
            " 'data/flower/test/dandelion/1776290427_9d8d5be6ac.jpg'\n",
            " 'data/flower/test/dandelion/2597655841_07fb2955a4.jpg'\n",
            " 'data/flower/test/dandelion/148180650_19a4b410db.jpg'\n",
            " 'data/flower/test/dandelion/3398195641_456872b48b_n.jpg'\n",
            " 'data/flower/test/dandelion/7262863194_682209e9fb.jpg'\n",
            " 'data/flower/test/dandelion/451965300_619b781dc9_m.jpg'\n",
            " 'data/flower/test/dandelion/7132676187_7a4265b16f_n.jpg'\n",
            " 'data/flower/test/dandelion/6983113346_21551e1b52_n.jpg'\n",
            " 'data/flower/test/dandelion/4669006062_6b3d260037_n.jpg'\n",
            " 'data/flower/test/dandelion/12094442595_297494dba4_m.jpg'\n",
            " 'data/flower/test/dandelion/5767676943_4f9c7323f3_n.jpg'\n",
            " 'data/flower/test/dandelion/2019520447_48b2354a20_m.jpg'\n",
            " 'data/flower/test/dandelion/7280217714_fb9ffccf2d_n.jpg'\n",
            " 'data/flower/test/dandelion/8757650550_113d7af3bd.jpg'\n",
            " 'data/flower/test/dandelion/4523862714_b41b459c88.jpg'\n",
            " 'data/flower/test/dandelion/12998979765_3de89e7195_n.jpg'\n",
            " 'data/flower/test/dandelion/13967344688_aa629dcdee_n.jpg'\n",
            " 'data/flower/test/dandelion/3458770076_17ed3a1225.jpg'\n",
            " 'data/flower/test/dandelion/7116950607_49b19102ba_n.jpg'\n",
            " 'data/flower/test/dandelion/2634666217_d5ef87c9f7_m.jpg'\n",
            " 'data/flower/test/dandelion/8740218495_23858355d8_n.jpg'\n",
            " 'data/flower/test/dandelion/14884028290_a1344eb446.jpg'\n",
            " 'data/flower/test/dandelion/7367491658_9eb4dc2384_m.jpg'\n",
            " 'data/flower/test/dandelion/4510350093_3700064215.jpg'\n",
            " 'data/flower/test/dandelion/5829610661_8439ba4a77_n.jpg'\n",
            " 'data/flower/test/dandelion/493696003_f93ffb3abd_n.jpg'\n",
            " 'data/flower/test/dandelion/5655177340_78fc36ce59_m.jpg'\n",
            " 'data/flower/test/dandelion/14335561523_f847f2f4f1.jpg'\n",
            " 'data/flower/test/dandelion/19626311985_58f1a79da3.jpg'\n",
            " 'data/flower/test/dandelion/8717161615_4c1e403083.jpg'\n",
            " 'data/flower/test/dandelion/2608937632_cfd93bc7cd.jpg'\n",
            " 'data/flower/test/dandelion/8707349105_6d06b543b0.jpg'\n",
            " 'data/flower/test/dandelion/8797114213_103535743c_m.jpg'\n",
            " 'data/flower/test/dandelion/8739657154_6db14796c9.jpg'\n",
            " 'data/flower/test/dandelion/8719032054_9a3ce4f0ff.jpg'\n",
            " 'data/flower/test/dandelion/2540640433_dedd577263.jpg'\n",
            " 'data/flower/test/dandelion/510677438_73e4b91c95_m.jpg'\n",
            " 'data/flower/test/dandelion/14065420729_9b388bf7cb_m.jpg'\n",
            " 'data/flower/test/dandelion/13652698934_d258a6ee8c.jpg'\n",
            " 'data/flower/test/dandelion/19613204505_da554eb56a_n.jpg'\n",
            " 'data/flower/test/dandelion/8733226215_161309f8ec.jpg'\n",
            " 'data/flower/test/dandelion/160456948_38c3817c6a_m.jpg'\n",
            " 'data/flower/test/dandelion/8689302980_9bd2f7b9fe_n.jpg'\n",
            " 'data/flower/test/dandelion/4635296297_9ce69e4a6e.jpg'\n",
            " 'data/flower/test/dandelion/14845607659_1be18c5d7f.jpg'\n",
            " 'data/flower/test/dandelion/8689302100_be76a16ccc_n.jpg'\n",
            " 'data/flower/test/dandelion/3459346147_faffff51c7_n.jpg'\n",
            " 'data/flower/test/dandelion/4552591312_02fe1dcc04_n.jpg'\n",
            " 'data/flower/test/dandelion/18995294384_77543e96b6_n.jpg'\n",
            " 'data/flower/test/dandelion/8905148527_ba9f55cd78.jpg'\n",
            " 'data/flower/test/dandelion/2462379970_6bd5560f4c_m.jpg'\n",
            " 'data/flower/test/dandelion/4632761610_768360d425.jpg'\n",
            " 'data/flower/test/dandelion/10043234166_e6dd915111_n.jpg'\n",
            " 'data/flower/test/dandelion/6985099958_5249a4688b.jpg'\n",
            " 'data/flower/test/dandelion/14278605962_d3cce5522f.jpg'\n",
            " 'data/flower/test/dandelion/10486992895_20b344ce2d_n.jpg'\n",
            " 'data/flower/test/dandelion/1273326361_b90ea56d0d_m.jpg'\n",
            " 'data/flower/test/dandelion/6044710875_0459796d1b_m.jpg'\n",
            " 'data/flower/test/dandelion/9300335851_cdf1cef7a9.jpg'\n",
            " 'data/flower/test/dandelion/5217892384_3edce91761_m.jpg'\n",
            " 'data/flower/test/dandelion/2521827947_9d237779bb_n.jpg'\n",
            " 'data/flower/test/dandelion/4574736702_b15ecf97d0_m.jpg'\n",
            " 'data/flower/test/dandelion/18970601002_d70bc883a9.jpg'\n",
            " 'data/flower/test/dandelion/3730618647_5725c692c3_m.jpg'\n",
            " 'data/flower/test/dandelion/18996965033_1d92e5c99e.jpg'\n",
            " 'data/flower/test/dandelion/459748276_69101b0cec_n.jpg'\n",
            " 'data/flower/test/dandelion/13386618495_3df1f1330d.jpg'\n",
            " 'data/flower/test/dandelion/14829055_2a2e646a8f_m.jpg'\n",
            " 'data/flower/test/dandelion/5033866477_a77cccba49_m.jpg'\n",
            " 'data/flower/test/dandelion/3198028825_fdfaa1d020.jpg'\n",
            " 'data/flower/test/dandelion/3554992110_81d8c9b0bd_m.jpg'\n",
            " 'data/flower/test/dandelion/14070457521_8eb41f65fa.jpg'\n",
            " 'data/flower/test/dandelion/2503034372_db7867de51_m.jpg'\n",
            " 'data/flower/test/dandelion/14002252932_64d5cbdac7.jpg'\n",
            " 'data/flower/test/dandelion/5572197407_a0047238a6.jpg'\n",
            " 'data/flower/test/dandelion/15358221063_2c6e548e84.jpg'\n",
            " 'data/flower/test/dandelion/14886963928_d4856f1eb6_n.jpg'\n",
            " 'data/flower/test/dandelion/14886860069_b84665a073.jpg'\n",
            " 'data/flower/test/dandelion/7843447416_847e6ba7f4_m.jpg'\n",
            " 'data/flower/test/dandelion/5725836812_a7d1c5540d_m.jpg'\n",
            " 'data/flower/test/dandelion/5608832856_f5d49de778.jpg'\n",
            " 'data/flower/test/dandelion/7132482331_01769e36e9_n.jpg'\n",
            " 'data/flower/test/dandelion/15139657325_74031c44fc.jpg'\n",
            " 'data/flower/test/dandelion/2518321294_dde5aa7c20_m.jpg'\n",
            " 'data/flower/test/dandelion/4151883194_e45505934d_n.jpg'\n",
            " 'data/flower/test/dandelion/7243478942_30bf542a2d_m.jpg'\n",
            " 'data/flower/test/dandelion/16716172029_2166d8717f_m.jpg'\n",
            " 'data/flower/test/dandelion/5757012454_c37f305b73.jpg'\n",
            " 'data/flower/test/dandelion/4258272381_65bd4b8191_m.jpg'\n",
            " 'data/flower/test/dandelion/2476098674_e6f39536f5_n.jpg'\n",
            " 'data/flower/test/dandelion/8681388520_c697dee897_n.jpg'\n",
            " 'data/flower/test/dandelion/8497389500_45636fdd14.jpg'\n",
            " 'data/flower/test/dandelion/15821571649_06c4b9a868_n.jpg'\n",
            " 'data/flower/test/dandelion/140951103_69847c0b7c.jpg'\n",
            " 'data/flower/test/dandelion/7280227122_7ea2bef7f4_n.jpg'\n",
            " 'data/flower/test/dandelion/3393060921_2328b752f4.jpg'\n",
            " 'data/flower/test/dandelion/5598591979_ed9af1b3e9_n.jpg'\n",
            " 'data/flower/test/dandelion/7004645518_ff0f862eff_n.jpg'\n",
            " 'data/flower/test/dandelion/8979087213_28f572174c.jpg'\n",
            " 'data/flower/test/dandelion/284497199_93a01f48f6.jpg'\n",
            " 'data/flower/test/dandelion/3675486971_d4c8683b54_n.jpg'\n",
            " 'data/flower/test/dandelion/7165651120_2279ebf6d1.jpg'\n",
            " 'data/flower/test/dandelion/425800274_27dba84fac_n.jpg'\n",
            " 'data/flower/test/dandelion/18282528206_7fb3166041.jpg'\n",
            " 'data/flower/test/dandelion/10617191174_9a01753241_n.jpg'\n",
            " 'data/flower/test/dandelion/8083321316_f62ea76f72_n.jpg'\n",
            " 'data/flower/test/dandelion/4858372040_52216eb0bd.jpg'\n",
            " 'data/flower/test/roses/8644003462_2272de26eb.jpg'\n",
            " 'data/flower/test/roses/8983268106_dc913d17d8_m.jpg'\n",
            " 'data/flower/test/roses/15712574834_2f121c7cf9_m.jpg'\n",
            " 'data/flower/test/roses/6347846687_3f0a7c3176.jpg'\n",
            " 'data/flower/test/roses/14154164774_3b39d36778.jpg'\n",
            " 'data/flower/test/roses/3026375835_a20ecdd140_m.jpg'\n",
            " 'data/flower/test/roses/19919867648_043cf02fc3.jpg'\n",
            " 'data/flower/test/roses/14683774134_6367640585.jpg'\n",
            " 'data/flower/test/roses/3203779656_3580151ea4_m.jpg'\n",
            " 'data/flower/test/roses/2273917656_6d6c038283.jpg'\n",
            " 'data/flower/test/roses/14810868100_87eb739f26_m.jpg'\n",
            " 'data/flower/test/roses/8775267816_726ddc6d92_n.jpg'\n",
            " 'data/flower/test/roses/6409000675_6eb6806e59.jpg'\n",
            " 'data/flower/test/roses/15509799653_0562d4a4fa.jpg'\n",
            " 'data/flower/test/roses/16449467833_d82aac5749_m.jpg'\n",
            " 'data/flower/test/roses/6105809987_8f3d7a8d67_n.jpg'\n",
            " 'data/flower/test/roses/1793211631_68c31a74dc.jpg'\n",
            " 'data/flower/test/roses/16258946661_f9739cdc0a.jpg'\n",
            " 'data/flower/test/roses/19988406792_68201f76e3_n.jpg'\n",
            " 'data/flower/test/roses/3634244527_e72c47842c_n.jpg'\n",
            " 'data/flower/test/roses/6347846935_51e3dc2481_n.jpg'\n",
            " 'data/flower/test/roses/2677417735_a697052d2d_n.jpg'\n",
            " 'data/flower/test/roses/319298955_0c72bd36bf.jpg'\n",
            " 'data/flower/test/roses/18990187093_09f2bff8fc_m.jpg'\n",
            " 'data/flower/test/roses/7551637034_55ae047756_n.jpg'\n",
            " 'data/flower/test/roses/2980099495_cf272e90ca_m.jpg'\n",
            " 'data/flower/test/roses/24781114_bc83aa811e_n.jpg'\n",
            " 'data/flower/test/roses/7409458444_0bfc9a0682_n.jpg'\n",
            " 'data/flower/test/roses/4754734410_94d98463a5.jpg'\n",
            " 'data/flower/test/roses/2225411981_6638c3e988.jpg'\n",
            " 'data/flower/test/roses/16209331331_343c899d38.jpg'\n",
            " 'data/flower/test/roses/4504220673_af754fcb40_n.jpg'\n",
            " 'data/flower/test/roses/17062080069_36ac7907d2_n.jpg'\n",
            " 'data/flower/test/roses/4702438868_278b9cf41c_n.jpg'\n",
            " 'data/flower/test/roses/568715474_bdb64ccc32.jpg'\n",
            " 'data/flower/test/roses/6687138903_ff6ae12758_n.jpg'\n",
            " 'data/flower/test/roses/6108118824_5b0231a56d.jpg'\n",
            " 'data/flower/test/roses/145862135_ab710de93c_n.jpg'\n",
            " 'data/flower/test/roses/9159362388_c6f4cf3812_n.jpg'\n",
            " 'data/flower/test/roses/14267691818_301aceda07.jpg'\n",
            " 'data/flower/test/roses/5050969148_a0090f762a.jpg'\n",
            " 'data/flower/test/roses/3231873181_faf2da6382.jpg'\n",
            " 'data/flower/test/roses/8671682526_7058143c99.jpg'\n",
            " 'data/flower/test/roses/269037241_07fceff56a_m.jpg'\n",
            " 'data/flower/test/roses/4764674741_82b8f93359_n.jpg'\n",
            " 'data/flower/test/roses/3873271620_1d9d314f01_n.jpg'\n",
            " 'data/flower/test/roses/218630974_5646dafc63_m.jpg'\n",
            " 'data/flower/test/roses/14943194730_f48b4d4547_n.jpg'\n",
            " 'data/flower/test/roses/3654988152_b11178bbcb.jpg'\n",
            " 'data/flower/test/roses/2059172936_032ffc12aa.jpg'\n",
            " 'data/flower/test/roses/22325299158_6e32e599f8_m.jpg'\n",
            " 'data/flower/test/roses/17165596357_392a12391f.jpg'\n",
            " 'data/flower/test/roses/16545641666_2781e542a0_m.jpg'\n",
            " 'data/flower/test/roses/16152205512_9d6cb80fb6.jpg'\n",
            " 'data/flower/test/roses/2535466143_5823e48b63.jpg'\n",
            " 'data/flower/test/roses/1801614110_bb9fa46830.jpg'\n",
            " 'data/flower/test/roses/5402157745_a384f0583d_n.jpg'\n",
            " 'data/flower/test/roses/15802657001_40fe77c030_m.jpg'\n",
            " 'data/flower/test/roses/494803274_f84f21d53a.jpg'\n",
            " 'data/flower/test/roses/509239741_28e2cfe492_m.jpg'\n",
            " 'data/flower/test/roses/19153732586_9de58c8f53_n.jpg'\n",
            " 'data/flower/test/roses/4256169180_55df2048a0.jpg'\n",
            " 'data/flower/test/roses/12202373204_34fb07205b.jpg'\n",
            " 'data/flower/test/roses/12434194695_a7c4e73c6b_n.jpg'\n",
            " 'data/flower/test/roses/8032328803_30afac8b07_m.jpg'\n",
            " 'data/flower/test/roses/5181899042_0a6ffe0c8a_n.jpg'\n",
            " 'data/flower/test/roses/1445228333_59a07e0801.jpg'\n",
            " 'data/flower/test/roses/19271410704_932d1f2c97_n.jpg'\n",
            " 'data/flower/test/roses/16149016979_23ef42b642_m.jpg'\n",
            " 'data/flower/test/roses/3556123230_936bf084a5_n.jpg'\n",
            " 'data/flower/test/roses/2258973326_03c0145f15_n.jpg'\n",
            " 'data/flower/test/roses/5777669976_a205f61e5b.jpg'\n",
            " 'data/flower/test/roses/14107161906_5737e0e4ec.jpg'\n",
            " 'data/flower/test/roses/16476788181_0e2ffc719a.jpg'\n",
            " 'data/flower/test/roses/3872230296_6c477309f3_n.jpg'\n",
            " 'data/flower/test/roses/9216321995_83df405ea9.jpg'\n",
            " 'data/flower/test/roses/20825078671_90b0389c70_m.jpg'\n",
            " 'data/flower/test/roses/512694812_48ba9c0b49_n.jpg'\n",
            " 'data/flower/test/roses/3236806990_a90c7bb520_m.jpg'\n",
            " 'data/flower/test/roses/2960709681_e95940c0f0_n.jpg'\n",
            " 'data/flower/test/roses/14166797345_d2ab9da518.jpg'\n",
            " 'data/flower/test/roses/4713531680_1110a2fa07_n.jpg'\n",
            " 'data/flower/test/roses/14172324538_2147808483_n.jpg'\n",
            " 'data/flower/test/roses/4644336779_acd973528c.jpg'\n",
            " 'data/flower/test/roses/1813435848_7852708394_n.jpg'\n",
            " 'data/flower/test/roses/3104672186_5f75647448_n.jpg'\n",
            " 'data/flower/test/roses/17305246720_1866d6303b.jpg'\n",
            " 'data/flower/test/roses/2325232198_751645d0bb_n.jpg'\n",
            " 'data/flower/test/roses/8667746487_781af9e615_n.jpg'\n",
            " 'data/flower/test/roses/756943228_e15a7b2318.jpg'\n",
            " 'data/flower/test/roses/9167147034_0a66ee3616_n.jpg'\n",
            " 'data/flower/test/roses/5721768347_2ec4d2247b_n.jpg'\n",
            " 'data/flower/test/roses/9614492283_66020fb4eb_n.jpg'\n",
            " 'data/flower/test/roses/14687731322_5613f76353.jpg'\n",
            " 'data/flower/test/roses/16666836810_216f50e9c3_m.jpg'\n",
            " 'data/flower/test/roses/8524505682_bda885af3a_n.jpg'\n",
            " 'data/flower/test/roses/6363976189_e7155e5f9c.jpg'\n",
            " 'data/flower/test/roses/6473543547_4fefdbd5dc.jpg'\n",
            " 'data/flower/test/roses/1461381091_aaaa663bbe_n.jpg'\n",
            " 'data/flower/test/roses/6231418894_7946a7712b_n.jpg'\n",
            " 'data/flower/test/roses/1666341535_99c6f7509f_n.jpg'\n",
            " 'data/flower/test/roses/5419629292_2f06e4b295.jpg'\n",
            " 'data/flower/test/roses/5487945052_bcb8e9fc8b_m.jpg'\n",
            " 'data/flower/test/roses/15190665092_5c1c37a066_m.jpg'\n",
            " 'data/flower/test/roses/16691277899_9433f39155_n.jpg'\n",
            " 'data/flower/test/roses/3661675690_ed2d05fa5f_n.jpg'\n",
            " 'data/flower/test/roses/8667101118_87ea757b15.jpg'\n",
            " 'data/flower/test/roses/15738649506_2b4c2fd933_m.jpg'\n",
            " 'data/flower/test/roses/3415176946_248afe9f32.jpg'\n",
            " 'data/flower/test/roses/2065522422_cfdd80044a_n.jpg'\n",
            " 'data/flower/test/roses/272481307_1eb47ba3e0_n.jpg'\n",
            " 'data/flower/test/roses/16772483324_09f24813a1_n.jpg'\n",
            " 'data/flower/test/roses/1446097778_97149b8362.jpg'\n",
            " 'data/flower/test/roses/8692040971_826614516f_n.jpg'\n",
            " 'data/flower/test/roses/3742155164_14b557a51c_n.jpg'\n",
            " 'data/flower/test/roses/8742493617_c2a9bf854f_m.jpg'\n",
            " 'data/flower/test/roses/22982871191_ec61e36939_n.jpg'\n",
            " 'data/flower/test/roses/15821959372_518b9dcf57_n.jpg'\n",
            " 'data/flower/test/roses/4724951744_61877ec101_n.jpg'\n",
            " 'data/flower/test/roses/8437935944_aab997560a_n.jpg'\n",
            " 'data/flower/test/roses/10503217854_e66a804309.jpg'\n",
            " 'data/flower/test/roses/3663244576_97f595cf4a.jpg'\n",
            " 'data/flower/test/roses/5961803532_9368212949_m.jpg'\n",
            " 'data/flower/test/roses/6255593451_b8a3aa8f7a_m.jpg'\n",
            " 'data/flower/test/roses/17051448596_69348f7fce_m.jpg'\n",
            " 'data/flower/test/roses/13279526615_a3b0059bec.jpg'\n",
            " 'data/flower/test/roses/7420699022_60fa574524_m.jpg'\n",
            " 'data/flower/test/roses/6969041818_a505baa68e_m.jpg'\n",
            " 'data/flower/test/sunflowers/12282924083_fb80aa17d4_n.jpg'\n",
            " 'data/flower/test/sunflowers/20658775992_1619cd0a9b_n.jpg'\n",
            " 'data/flower/test/sunflowers/7820305664_82148f3bfb_n.jpg'\n",
            " 'data/flower/test/sunflowers/21374127408_5ffbe87bb2.jpg'\n",
            " 'data/flower/test/sunflowers/13648603305_1268eda8b7_n.jpg'\n",
            " 'data/flower/test/sunflowers/9610098411_f1613c8e14.jpg'\n",
            " 'data/flower/test/sunflowers/45045005_57354ee844.jpg'\n",
            " 'data/flower/test/sunflowers/9448615838_04078d09bf_n.jpg'\n",
            " 'data/flower/test/sunflowers/2689228449_e0be72cf00_n.jpg'\n",
            " 'data/flower/test/sunflowers/3596902268_049e33a2cb_n.jpg'\n",
            " 'data/flower/test/sunflowers/4914793782_d0ea760791.jpg'\n",
            " 'data/flower/test/sunflowers/4932143849_018486cbf7.jpg'\n",
            " 'data/flower/test/sunflowers/5018120483_cc0421b176_m.jpg'\n",
            " 'data/flower/test/sunflowers/23356825566_f5885875f2.jpg'\n",
            " 'data/flower/test/sunflowers/6908789145_814d448bb1_n.jpg'\n",
            " 'data/flower/test/sunflowers/5957007921_62333981d2_n.jpg'\n",
            " 'data/flower/test/sunflowers/7176736574_14446539cb_n.jpg'\n",
            " 'data/flower/test/sunflowers/2950505226_529e013bf7_m.jpg'\n",
            " 'data/flower/test/sunflowers/7652532108_01ef94c476.jpg'\n",
            " 'data/flower/test/sunflowers/184682095_46f8607278.jpg'\n",
            " 'data/flower/test/sunflowers/5027895361_ace3b731e5_n.jpg'\n",
            " 'data/flower/test/sunflowers/14932787983_d6e05f2434_m.jpg'\n",
            " 'data/flower/test/sunflowers/6166888942_7058198713_m.jpg'\n",
            " 'data/flower/test/sunflowers/14348961225_09bd803317_n.jpg'\n",
            " 'data/flower/test/sunflowers/20621698991_dcb323911d.jpg'\n",
            " 'data/flower/test/sunflowers/20777358950_c63ea569a1.jpg'\n",
            " 'data/flower/test/sunflowers/15054753070_4f6ae0e763_m.jpg'\n",
            " 'data/flower/test/sunflowers/4814106562_7c3564d2d9_n.jpg'\n",
            " 'data/flower/test/sunflowers/210076535_80951bc5d5.jpg'\n",
            " 'data/flower/test/sunflowers/147804446_ef9244c8ce_m.jpg'\n",
            " 'data/flower/test/sunflowers/5979111025_3bcae48ae6_n.jpg'\n",
            " 'data/flower/test/sunflowers/3951246342_930138610b_n.jpg'\n",
            " 'data/flower/test/sunflowers/4847062576_bae870479c_n.jpg'\n",
            " 'data/flower/test/sunflowers/145303599_2627e23815_n.jpg'\n",
            " 'data/flower/test/sunflowers/5923649444_a823e534e9.jpg'\n",
            " 'data/flower/test/sunflowers/20171662239_f69b6c12bd_n.jpg'\n",
            " 'data/flower/test/sunflowers/5955501969_e42f038a6f_n.jpg'\n",
            " 'data/flower/test/sunflowers/4414081772_8a0e8a1327.jpg'\n",
            " 'data/flower/test/sunflowers/18843967474_9cb552716b.jpg'\n",
            " 'data/flower/test/sunflowers/6606741847_f0198d83ff.jpg'\n",
            " 'data/flower/test/sunflowers/2960610406_b61930727f_n.jpg'\n",
            " 'data/flower/test/sunflowers/274846229_990e976683_n.jpg'\n",
            " 'data/flower/test/sunflowers/7728953426_abd179ab63.jpg'\n",
            " 'data/flower/test/sunflowers/9558627290_353a14ba0b_m.jpg'\n",
            " 'data/flower/test/sunflowers/19710925313_31682fa22b_m.jpg'\n",
            " 'data/flower/test/sunflowers/12471441503_d188b5f31a_m.jpg'\n",
            " 'data/flower/test/sunflowers/6953297_8576bf4ea3.jpg'\n",
            " 'data/flower/test/sunflowers/2694860538_b95d60122c_m.jpg'\n",
            " 'data/flower/test/sunflowers/4626721387_88f89d5cc9_n.jpg'\n",
            " 'data/flower/test/sunflowers/200011914_93f57ed68b.jpg'\n",
            " 'data/flower/test/sunflowers/4813483281_f3707a71e7_n.jpg'\n",
            " 'data/flower/test/sunflowers/215798352_184d8040d1.jpg'\n",
            " 'data/flower/test/sunflowers/6606813305_c992231d29_m.jpg'\n",
            " 'data/flower/test/sunflowers/14955545254_324cd4ee75.jpg'\n",
            " 'data/flower/test/sunflowers/16975010069_7afd290657_m.jpg'\n",
            " 'data/flower/test/sunflowers/6140693467_211a135b6d.jpg'\n",
            " 'data/flower/test/sunflowers/14144522269_bc20029375_m.jpg'\n",
            " 'data/flower/test/sunflowers/2823659190_afdabee45c.jpg'\n",
            " 'data/flower/test/sunflowers/7369484298_332f69bd88_n.jpg'\n",
            " 'data/flower/test/sunflowers/9558628596_722c29ec60_m.jpg'\n",
            " 'data/flower/test/sunflowers/5069564563_ae03792c3c_m.jpg'\n",
            " 'data/flower/test/sunflowers/9359374034_21fb12d613_n.jpg'\n",
            " 'data/flower/test/sunflowers/8929288228_6795bcb1fe.jpg'\n",
            " 'data/flower/test/sunflowers/3665455426_9cd1c3af4a_n.jpg'\n",
            " 'data/flower/test/sunflowers/4932735362_6e1017140f.jpg'\n",
            " 'data/flower/test/sunflowers/3731075939_6c92d7fe68_m.jpg'\n",
            " 'data/flower/test/sunflowers/200557979_a16112aac1_n.jpg'\n",
            " 'data/flower/test/sunflowers/20406385204_469f6749e2_n.jpg'\n",
            " 'data/flower/test/sunflowers/14928117202_139d2142cc_n.jpg'\n",
            " 'data/flower/test/sunflowers/7510285306_ba8f80c382_n.jpg'\n",
            " 'data/flower/test/sunflowers/151898652_b5f1c70b98_n.jpg'\n",
            " 'data/flower/test/sunflowers/6199086734_b7ddc65816_m.jpg'\n",
            " 'data/flower/test/sunflowers/821368661_4ab4343f5a.jpg'\n",
            " 'data/flower/test/sunflowers/3893436870_034b79d118_n.jpg'\n",
            " 'data/flower/test/sunflowers/4895721242_89014e723c_n.jpg'\n",
            " 'data/flower/test/sunflowers/4895720722_8247f2015b_n.jpg'\n",
            " 'data/flower/test/sunflowers/9538283930_0faea083bb_n.jpg'\n",
            " 'data/flower/test/sunflowers/9651392844_77f90589ba_n.jpg'\n",
            " 'data/flower/test/sunflowers/4932735566_2327bf319a.jpg'\n",
            " 'data/flower/test/sunflowers/4933229561_881d4673e7_m.jpg'\n",
            " 'data/flower/test/sunflowers/4341530649_c17bbc5d01.jpg'\n",
            " 'data/flower/test/sunflowers/3846717708_ea11383ed8.jpg'\n",
            " 'data/flower/test/sunflowers/4933229357_1c5cc03f65_m.jpg'\n",
            " 'data/flower/test/sunflowers/5139969631_743880e01d_n.jpg'\n",
            " 'data/flower/test/sunflowers/14460075029_5cd715bb72_m.jpg'\n",
            " 'data/flower/test/sunflowers/3575811488_a31714472a.jpg'\n",
            " 'data/flower/test/sunflowers/9610371852_179e7781ce.jpg'\n",
            " 'data/flower/test/sunflowers/10386525695_2c38fea555_n.jpg'\n",
            " 'data/flower/test/sunflowers/8174935013_b16626b49b.jpg'\n",
            " 'data/flower/test/sunflowers/6627521877_6e43fb3c49_m.jpg'\n",
            " 'data/flower/test/sunflowers/3514340206_efb8198a80_n.jpg'\n",
            " 'data/flower/test/sunflowers/5437996076_cf7e2ac32e_n.jpg'\n",
            " 'data/flower/test/sunflowers/14741907467_fab96f3b2b_n.jpg'\n",
            " 'data/flower/test/sunflowers/5357144886_b78f4782eb.jpg'\n",
            " 'data/flower/test/sunflowers/15054865768_2cc87ac9d4_m.jpg'\n",
            " 'data/flower/test/sunflowers/14741812319_e1d32ffb84_n.jpg'\n",
            " 'data/flower/test/sunflowers/7820626738_3be6a52e4e_n.jpg'\n",
            " 'data/flower/test/sunflowers/9460336948_6ae968be93.jpg'\n",
            " 'data/flower/test/sunflowers/16143151468_4f3c033e33.jpg'\n",
            " 'data/flower/test/sunflowers/5896354497_6a19162741.jpg'\n",
            " 'data/flower/test/sunflowers/127192624_afa3d9cb84.jpg'\n",
            " 'data/flower/test/sunflowers/14925398301_55a180f919_n.jpg'\n",
            " 'data/flower/test/sunflowers/2979133707_84aab35b5d.jpg'\n",
            " 'data/flower/test/sunflowers/5067864967_19928ca94c_m.jpg'\n",
            " 'data/flower/test/sunflowers/2816256710_a2d3616fae.jpg'\n",
            " 'data/flower/test/sunflowers/22255608949_172d7c8d22_m.jpg'\n",
            " 'data/flower/test/sunflowers/5970868068_fe1c8b282e_n.jpg'\n",
            " 'data/flower/test/sunflowers/9427945592_07a2676945_n.jpg'\n",
            " 'data/flower/test/sunflowers/3784815653_5df39aa9c2_m.jpg'\n",
            " 'data/flower/test/sunflowers/7176729016_d73ff2211e.jpg'\n",
            " 'data/flower/test/sunflowers/10386525005_fd0b7d6c55_n.jpg'\n",
            " 'data/flower/test/sunflowers/8480886751_71d88bfdc0_n.jpg'\n",
            " 'data/flower/test/sunflowers/20410697750_c43973d1eb.jpg'\n",
            " 'data/flower/test/sunflowers/1596293240_2d5b53495a_m.jpg'\n",
            " 'data/flower/test/sunflowers/5015462205_440898fe41_n.jpg'\n",
            " 'data/flower/test/sunflowers/864957037_c75373d1c5.jpg'\n",
            " 'data/flower/test/sunflowers/12471791574_bb1be83df4.jpg'\n",
            " 'data/flower/test/sunflowers/7804213238_1d92ae5edb_m.jpg'\n",
            " 'data/flower/test/sunflowers/9485002920_59af6f4cac.jpg'\n",
            " 'data/flower/test/sunflowers/14266917699_91b207888e.jpg'\n",
            " 'data/flower/test/sunflowers/21984860006_20dfacea1c_m.jpg'\n",
            " 'data/flower/test/sunflowers/15122112402_cafa41934f.jpg'\n",
            " 'data/flower/test/sunflowers/4869189730_f47c124cda_n.jpg'\n",
            " 'data/flower/test/sunflowers/5979111555_61b400c070_n.jpg'\n",
            " 'data/flower/test/sunflowers/14646283472_50a3ae1395.jpg'\n",
            " 'data/flower/test/sunflowers/2723995667_31f32294b4.jpg'\n",
            " 'data/flower/test/sunflowers/6606806621_5267acdd38.jpg'\n",
            " 'data/flower/test/sunflowers/26254755_1bfc494ef1_n.jpg'\n",
            " 'data/flower/test/sunflowers/16832961488_5f7e70eb5e_n.jpg'\n",
            " 'data/flower/test/sunflowers/15030133005_9728102622_z.jpg'\n",
            " 'data/flower/test/sunflowers/4933229095_f7e4218b28.jpg'\n",
            " 'data/flower/test/sunflowers/21995435890_e5672244a4_m.jpg'\n",
            " 'data/flower/test/sunflowers/4664737020_b4c61aacd3_n.jpg'\n",
            " 'data/flower/test/sunflowers/5830614551_e460a1215c.jpg'\n",
            " 'data/flower/test/sunflowers/3146795631_d062f233c1.jpg'\n",
            " 'data/flower/test/sunflowers/16656015339_2ccb7cd18d.jpg'\n",
            " 'data/flower/test/sunflowers/14121915990_4b76718077_m.jpg'\n",
            " 'data/flower/test/sunflowers/15066430311_fb57fa92b0_m.jpg'\n",
            " 'data/flower/test/sunflowers/5979668702_fdaec9e164_n.jpg'\n",
            " 'data/flower/test/tulips/17862445825_f7031d6f26.jpg'\n",
            " 'data/flower/test/tulips/4599815420_8ee42c2382.jpg'\n",
            " 'data/flower/test/tulips/7447655334_e8f805ab95_m.jpg'\n",
            " 'data/flower/test/tulips/3516269489_cef36e87a6.jpg'\n",
            " 'data/flower/test/tulips/16670377091_87987f50a4_n.jpg'\n",
            " 'data/flower/test/tulips/7144016605_e159b6c06b_m.jpg'\n",
            " 'data/flower/test/tulips/14487705209_ea723109e1_m.jpg'\n",
            " 'data/flower/test/tulips/7068715863_a534ac7884_n.jpg'\n",
            " 'data/flower/test/tulips/13561966423_e5c641fe11.jpg'\n",
            " 'data/flower/test/tulips/2412250315_a04171da51_n.jpg'\n",
            " 'data/flower/test/tulips/8713392604_90631fb809_n.jpg'\n",
            " 'data/flower/test/tulips/7205698252_b972087cc2.jpg'\n",
            " 'data/flower/test/tulips/14068295074_cd8b85bffa.jpg'\n",
            " 'data/flower/test/tulips/17318339476_54479b6660_n.jpg'\n",
            " 'data/flower/test/tulips/18270448366_d5676dec64_z.jpg'\n",
            " 'data/flower/test/tulips/14057246122_8598b665bd.jpg'\n",
            " 'data/flower/test/tulips/8712270665_57b5bda0a2_n.jpg'\n",
            " 'data/flower/test/tulips/8454719295_4276c0e9c5_n.jpg'\n",
            " 'data/flower/test/tulips/14015957646_8317a0f1d9_n.jpg'\n",
            " 'data/flower/test/tulips/14064735842_a946fba1ef_n.jpg'\n",
            " 'data/flower/test/tulips/8677713853_1312f65e71.jpg'\n",
            " 'data/flower/test/tulips/13562266594_69b807f90c.jpg'\n",
            " 'data/flower/test/tulips/14017640283_c417141832_n.jpg'\n",
            " 'data/flower/test/tulips/13976206001_fd1c2cbd60.jpg'\n",
            " 'data/flower/test/tulips/14067761295_7cfe6a42e9.jpg'\n",
            " 'data/flower/test/tulips/14068200854_5c13668df9_m.jpg'\n",
            " 'data/flower/test/tulips/8713387500_6a9138b41b_n.jpg'\n",
            " 'data/flower/test/tulips/5635347336_bc1400e939_n.jpg'\n",
            " 'data/flower/test/tulips/54895006_55b49052dc.jpg'\n",
            " 'data/flower/test/tulips/8762189906_8223cef62f.jpg'\n",
            " 'data/flower/test/tulips/4890786831_91bb82a9e4_n.jpg'\n",
            " 'data/flower/test/tulips/15756524087_823cf86bd8_m.jpg'\n",
            " 'data/flower/test/tulips/8904780994_8867d64155_n.jpg'\n",
            " 'data/flower/test/tulips/5680695867_baff72fc7c.jpg'\n",
            " 'data/flower/test/tulips/8713398614_88202e452e_n.jpg'\n",
            " 'data/flower/test/tulips/467702445_b8676f60fb_n.jpg'\n",
            " 'data/flower/test/tulips/5730908127_da871df0f8.jpg'\n",
            " 'data/flower/test/tulips/3502251824_3be758edc6_m.jpg'\n",
            " 'data/flower/test/tulips/2436998042_4906ea07af.jpg'\n",
            " 'data/flower/test/tulips/113291410_1bdc718ed8_n.jpg'\n",
            " 'data/flower/test/tulips/13910544560_9140dd547e.jpg'\n",
            " 'data/flower/test/tulips/17066864992_1cbc4fc908.jpg'\n",
            " 'data/flower/test/tulips/4582198748_20fa7caaa1.jpg'\n",
            " 'data/flower/test/tulips/7003964080_4566470798_n.jpg'\n",
            " 'data/flower/test/tulips/738207467_fc59cfcd9b_z.jpg'\n",
            " 'data/flower/test/tulips/7094271655_79a6f972c1_n.jpg'\n",
            " 'data/flower/test/tulips/4042180234_64cd2859c9_m.jpg'\n",
            " 'data/flower/test/tulips/3511104954_54eace015c_n.jpg'\n",
            " 'data/flower/test/tulips/14255917256_84c23c572b.jpg'\n",
            " 'data/flower/test/tulips/13513616525_2ee0f049e1.jpg'\n",
            " 'data/flower/test/tulips/7166554924_432aaae4b2_n.jpg'\n",
            " 'data/flower/test/tulips/16937554595_3e1de22f9c.jpg'\n",
            " 'data/flower/test/tulips/14087792403_f34f37ba3b_m.jpg'\n",
            " 'data/flower/test/tulips/4562423077_00b16240dc_n.jpg'\n",
            " 'data/flower/test/tulips/5670916806_df4316006f_n.jpg'\n",
            " 'data/flower/test/tulips/14487943607_651e8062a1_m.jpg'\n",
            " 'data/flower/test/tulips/16485607329_e66d5960bc_m.jpg'\n",
            " 'data/flower/test/tulips/8710148289_6fc196a0f8_n.jpg'\n",
            " 'data/flower/test/tulips/1353748522_b9c630b162.jpg'\n",
            " 'data/flower/test/tulips/16062072523_1be3c0b61f.jpg'\n",
            " 'data/flower/test/tulips/5637140035_e6c5514f54.jpg'\n",
            " 'data/flower/test/tulips/16303377824_6e9128b4bd.jpg'\n",
            " 'data/flower/test/tulips/16702117379_c25bff70e9.jpg'\n",
            " 'data/flower/test/tulips/13974542496_e4b5d1c913_n.jpg'\n",
            " 'data/flower/test/tulips/5700466891_2bcb17fa68_n.jpg'\n",
            " 'data/flower/test/tulips/8394186551_28eed83a94_m.jpg'\n",
            " 'data/flower/test/tulips/5665708521_799585d229_n.jpg'\n",
            " 'data/flower/test/tulips/4312181724_16dab26afb_n.jpg'\n",
            " 'data/flower/test/tulips/7481204112_e3c57dd40a_n.jpg'\n",
            " 'data/flower/test/tulips/4497973347_57480ffee9_m.jpg'\n",
            " 'data/flower/test/tulips/14027372499_30f934d24f_m.jpg'\n",
            " 'data/flower/test/tulips/12548574923_5e90f4ceea.jpg'\n",
            " 'data/flower/test/tulips/8712230357_1298b8513b.jpg'\n",
            " 'data/flower/test/tulips/5208680166_c4372477ef_n.jpg'\n",
            " 'data/flower/test/tulips/5674707464_dc18de05b1.jpg'\n",
            " 'data/flower/test/tulips/12873145295_438b8197a7_n.jpg'\n",
            " 'data/flower/test/tulips/5543457754_89c44c88de_n.jpg'\n",
            " 'data/flower/test/tulips/12883412424_cb5086b43f_n.jpg'\n",
            " 'data/flower/test/tulips/6227136437_6117068599_m.jpg'\n",
            " 'data/flower/test/tulips/3991423020_9aaf2b5974_n.jpg'\n",
            " 'data/flower/test/tulips/440714501_9f8268e1b0.jpg'\n",
            " 'data/flower/test/tulips/485415743_eeb5d7c1a5.jpg'\n",
            " 'data/flower/test/tulips/3455026124_d66cafb9fc.jpg'\n",
            " 'data/flower/test/tulips/14067778605_0285b7cc3a.jpg'\n",
            " 'data/flower/test/tulips/9444202147_405290415b_n.jpg'\n",
            " 'data/flower/test/tulips/8673416556_639f5c88f1_n.jpg'\n",
            " 'data/flower/test/tulips/5417115048_3b78d6c875_n.jpg'\n",
            " 'data/flower/test/tulips/2426847695_4b8409402e_n.jpg'\n",
            " 'data/flower/test/tulips/8708856019_f3be2353a4_n.jpg'\n",
            " 'data/flower/test/tulips/17781940352_a45e4289a5.jpg'\n",
            " 'data/flower/test/tulips/17189456156_6fc1067831.jpg'\n",
            " 'data/flower/test/tulips/14068348874_7b36c99f6a.jpg'\n",
            " 'data/flower/test/tulips/6227136683_262c6be56b.jpg'\n",
            " 'data/flower/test/tulips/7179796338_05e8b1c87b.jpg'\n",
            " 'data/flower/test/tulips/14127532150_112823a8f6.jpg'\n",
            " 'data/flower/test/tulips/8614237582_74417799f4_m.jpg'\n",
            " 'data/flower/test/tulips/6936380780_19c26c918a.jpg'\n",
            " 'data/flower/test/tulips/2374855021_21959b40c0_n.jpg'\n",
            " 'data/flower/test/tulips/2427626706_ffdf697f84_n.jpg'\n",
            " 'data/flower/test/tulips/4681062529_36186617d9.jpg'\n",
            " 'data/flower/test/tulips/9446982168_06c4d71da3_n.jpg'\n",
            " 'data/flower/test/tulips/14093884601_c87b5cd663_n.jpg'\n",
            " 'data/flower/test/tulips/8713388322_e5ae26263b_n.jpg'\n",
            " 'data/flower/test/tulips/8554190977_37ac747799_m.jpg'\n",
            " 'data/flower/test/tulips/2272006181_785f1be94f_n.jpg'\n",
            " 'data/flower/test/tulips/100930342_92e8746431_n.jpg'\n",
            " 'data/flower/test/tulips/16594995743_ce72c61201_n.jpg'\n",
            " 'data/flower/test/tulips/6267021825_a8316e0dcc_m.jpg'\n",
            " 'data/flower/test/tulips/14064731501_ea14b58161.jpg'\n",
            " 'data/flower/test/tulips/15275478257_fbd5850708_n.jpg'\n",
            " 'data/flower/test/tulips/8659691170_09db83d023.jpg'\n",
            " 'data/flower/test/tulips/4553203984_9cb9312240_n.jpg'\n",
            " 'data/flower/test/tulips/15516736553_b169b67195_n.jpg'\n",
            " 'data/flower/test/tulips/4550117239_5907aaba4c.jpg'\n",
            " 'data/flower/test/tulips/14053292975_fdc1093571_n.jpg'\n",
            " 'data/flower/test/tulips/2256230386_08b54ca760.jpg'\n",
            " 'data/flower/test/tulips/112650879_82adc2cc04_n.jpg'\n",
            " 'data/flower/test/tulips/8712243901_54d686319e_m.jpg'\n",
            " 'data/flower/test/tulips/13472141763_f2517e7f0d.jpg'\n",
            " 'data/flower/test/tulips/14254839301_ffb19c6445_n.jpg'\n",
            " 'data/flower/test/tulips/8520488975_a50d377f91.jpg'\n",
            " 'data/flower/test/tulips/13857267684_d2a4b2630f_n.jpg'\n",
            " 'data/flower/test/tulips/3238068295_b2a7b17f48_n.jpg'\n",
            " 'data/flower/test/tulips/8686332852_c6dcb2e86b.jpg'\n",
            " 'data/flower/test/tulips/17908793211_ff0f1f81d3_n.jpg'\n",
            " 'data/flower/test/tulips/6539831765_c21b68910e_n.jpg'\n",
            " 'data/flower/test/tulips/12916017805_1cde91a891_n.jpg'\n",
            " 'data/flower/test/tulips/434146736_310a42d9cb_m.jpg'\n",
            " 'data/flower/test/tulips/14093565032_a8f1e349d1.jpg'\n",
            " 'data/flower/test/tulips/16951623209_00fb7ec1b1_n.jpg'\n",
            " 'data/flower/test/tulips/5811022098_2523ca4e82.jpg'\n",
            " 'data/flower/test/tulips/2243427551_809b603992_z.jpg'\n",
            " 'data/flower/test/tulips/8712263493_3db76c5f82.jpg'\n",
            " 'data/flower/test/tulips/4300258119_b03f2f956e.jpg'\n",
            " 'data/flower/test/tulips/8712267391_c756f18ee7_n.jpg'\n",
            " 'data/flower/test/tulips/466409031_4c10294db5_m.jpg'\n",
            " 'data/flower/test/tulips/8717900362_2aa508e9e5.jpg'\n",
            " 'data/flower/test/tulips/8511683706_4173683d45_m.jpg'\n",
            " 'data/flower/test/tulips/14097366955_84ef6369f2.jpg'\n",
            " 'data/flower/test/tulips/16677542612_a78a8ca8b3_m.jpg'\n",
            " 'data/flower/test/tulips/3600510954_a51bfc5440_n.jpg'\n",
            " 'data/flower/test/tulips/8708209606_d3aede4801.jpg'\n",
            " 'data/flower/test/tulips/13530786873_0d34880300_n.jpg'\n",
            " 'data/flower/test/tulips/13513846963_c3d5e9fb1d_n.jpg'\n",
            " 'data/flower/test/tulips/6325571510_7544b27e57_n.jpg'\n",
            " 'data/flower/test/tulips/5661431592_cea1108261_n.jpg'\n",
            " 'data/flower/test/tulips/5682463466_d3e641cb8b.jpg'\n",
            " 'data/flower/test/tulips/14103897845_7986002615.jpg'\n",
            " 'data/flower/test/tulips/3502974120_9f1eceaf8b_n.jpg'\n",
            " 'data/flower/test/tulips/12764617214_12211c6a0c_m.jpg'\n",
            " 'data/flower/test/tulips/17309951996_552d632cbb_n.jpg'\n",
            " 'data/flower/test/tulips/5674127693_1ddbd81097.jpg'\n",
            " 'data/flower/test/tulips/405035580_94b793e71d.jpg'\n",
            " 'data/flower/test/tulips/3991742794_edebc6c8a0_n.jpg'\n",
            " 'data/flower/test/tulips/3540595981_73f14d1227_n.jpg'\n",
            " 'data/flower/test/tulips/7002703410_3e97b29da5_n.jpg'\n",
            " 'data/flower/test/tulips/8729501081_b993185542_m.jpg'\n",
            " 'data/flower/test/tulips/14278331403_4c475f9a9b.jpg'\n",
            " 'data/flower/test/tulips/2425067141_b27043a800_m.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO DO: Create your own model class definition and train your model with the training set"
      ],
      "metadata": {
        "id": "J12b_9w5F0uC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "TO DO: Evalute your trained model with the test set."
      ],
      "metadata": {
        "id": "aVwHJWeRF6xM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Flower(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 8, 3)\n",
        "        self.fc1 = nn.Linear(7200, 500)\n",
        "        self.fc2 = nn.Linear(500, 124)\n",
        "        self.fc3 = nn.Linear(124, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "y3C9PebYqoyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import binarize\n",
        "epochs = 100\n",
        "labelDict = {\n",
        "  \"daisy\" : 1,\n",
        "  \"dandelion\" : 2,\n",
        "  \"roses\" : 3,\n",
        "  \"sunflowers\" : 4,\n",
        "  \"tulips\" : 5\n",
        "}\n",
        "\n",
        "model = Flower()\n",
        "model.eval()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "for epoch in range(epochs):\n",
        "  hit = 0\n",
        "  tot = 0\n",
        "  batch_num = 0\n",
        "  for i, data in enumerate(imgLoader, 0):\n",
        "    batch_num += 1\n",
        "    inputs, labels, _ = data\n",
        "    lables_binary = []\n",
        "    for i in enumerate(labels):\n",
        "      if labelDict[i[1]] == 1:\n",
        "        binary = [1,0,0,0,0]\n",
        "      elif labelDict[i[1]] == 2:\n",
        "        binary = [0,1,0,0,0]\n",
        "      elif labelDict[i[1]] == 3:\n",
        "        binary = [0,0,1,0,0]\n",
        "      elif labelDict[i[1]] == 4:\n",
        "        binary = [0,0,0,1,0]\n",
        "      elif labelDict[i[1]] == 5:\n",
        "        binary = [0,0,0,0,1]\n",
        "      lables_binary.append(binary)\n",
        "\n",
        "    labels = np.array(lables_binary)\n",
        "    labels = torch.from_numpy(labels).type(torch.FloatTensor)\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    print(\"Training loss : {}\".format(loss))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    output = outputs.detach().cpu().numpy()\n",
        "    output_n = (output == output.max(axis=1)[:,None]).astype(int)\n",
        "    # output_n = binarize(output.reshape(-1,1), threshold=0.5)\n",
        "    # output_n = output_n.reshape((int(output_n.shape[0]/5), 5))\n",
        "    for i in range(output_n.shape[0]):\n",
        "      if np.array_equal(output_n[i], lables_binary[i]):\n",
        "        hit += 1\n",
        "        tot += 1\n",
        "      else:\n",
        "        tot += 1\n",
        "  print(\"===========================================================\")\n",
        "  print(\"Training Acc on Epoch {}\".format(epoch) + \": {}\".format(hit/tot))\n",
        "  print(\"===========================================================\")\n",
        "\n",
        "  hit = 0\n",
        "  tot = 0\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(imgLoader_test, 0):\n",
        "      batch_num += 1\n",
        "      inputs, labels, _ = data\n",
        "      lables_binary = []\n",
        "      for i in enumerate(labels):\n",
        "        if labelDict[i[1]] == 1:\n",
        "          binary = [1,0,0,0,0]\n",
        "        elif labelDict[i[1]] == 2:\n",
        "          binary = [0,1,0,0,0]\n",
        "        elif labelDict[i[1]] == 3:\n",
        "          binary = [0,0,1,0,0]\n",
        "        elif labelDict[i[1]] == 4:\n",
        "          binary = [0,0,0,1,0]\n",
        "        elif labelDict[i[1]] == 5:\n",
        "          binary = [0,0,0,0,1]\n",
        "        lables_binary.append(binary)\n",
        "\n",
        "      labels = np.array(lables_binary)\n",
        "      labels = torch.from_numpy(labels).type(torch.FloatTensor)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      output = outputs.detach().cpu().numpy()\n",
        "      output_n = (output == output.max(axis=1)[:,None]).astype(int)\n",
        "      for i in range(output_n.shape[0]):\n",
        "        if np.array_equal(output_n[i], lables_binary[i]):\n",
        "          hit += 1\n",
        "          tot += 1\n",
        "        else:\n",
        "          tot += 1\n",
        "    print(\"===========================================================\")\n",
        "    print(\"Test Acc on Epoch {}\".format(epoch) + \": {}\".format(hit/tot))\n",
        "    print(\"===========================================================\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnxSAm1y2rQM",
        "outputId": "38a7b5b9-c0be-4310-839e-cb1d7fdd6230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss : 1.6120363473892212\n",
            "Training loss : 1.60155189037323\n",
            "Training loss : 1.6051491498947144\n",
            "Training loss : 1.5935951471328735\n",
            "Training loss : 1.5743557214736938\n",
            "Training loss : 1.5875228643417358\n",
            "===========================================================\n",
            "Training Acc on Epoch 0: 0.23851650221163662\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 0: 0.290575025518884\n",
            "===========================================================\n",
            "Training loss : 1.531959056854248\n",
            "Training loss : 1.523092269897461\n",
            "Training loss : 1.5164031982421875\n",
            "Training loss : 1.4904650449752808\n",
            "Training loss : 1.4781701564788818\n",
            "Training loss : 1.4524182081222534\n",
            "===========================================================\n",
            "Training Acc on Epoch 1: 0.3337870023817625\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 1: 0.3763184756719973\n",
            "===========================================================\n",
            "Training loss : 1.447386384010315\n",
            "Training loss : 1.4325408935546875\n",
            "Training loss : 1.3951083421707153\n",
            "Training loss : 1.4560606479644775\n",
            "Training loss : 1.3478319644927979\n",
            "Training loss : 1.3745853900909424\n",
            "===========================================================\n",
            "Training Acc on Epoch 2: 0.4011568560734944\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 2: 0.4521946240217761\n",
            "===========================================================\n",
            "Training loss : 1.3305162191390991\n",
            "Training loss : 1.3538562059402466\n",
            "Training loss : 1.3486459255218506\n",
            "Training loss : 1.2907906770706177\n",
            "Training loss : 1.258554220199585\n",
            "Training loss : 1.2630409002304077\n",
            "===========================================================\n",
            "Training Acc on Epoch 3: 0.4450493365090167\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 3: 0.46750595440626064\n",
            "===========================================================\n",
            "Training loss : 1.2532954216003418\n",
            "Training loss : 1.1879656314849854\n",
            "Training loss : 1.2351864576339722\n",
            "Training loss : 1.2217267751693726\n",
            "Training loss : 1.2685635089874268\n",
            "Training loss : 1.2381410598754883\n",
            "===========================================================\n",
            "Training Acc on Epoch 4: 0.4746512419190201\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 4: 0.4879210615855733\n",
            "===========================================================\n",
            "Training loss : 1.197589635848999\n",
            "Training loss : 1.2251698970794678\n",
            "Training loss : 1.1364474296569824\n",
            "Training loss : 1.160582423210144\n",
            "Training loss : 1.2040642499923706\n",
            "Training loss : 1.2057197093963623\n",
            "===========================================================\n",
            "Training Acc on Epoch 5: 0.4937053419530453\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 5: 0.5011908812521265\n",
            "===========================================================\n",
            "Training loss : 1.2114590406417847\n",
            "Training loss : 1.1213829517364502\n",
            "Training loss : 1.1609737873077393\n",
            "Training loss : 1.1115080118179321\n",
            "Training loss : 1.1063522100448608\n",
            "Training loss : 1.1600757837295532\n",
            "===========================================================\n",
            "Training Acc on Epoch 6: 0.5267097652262674\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 6: 0.5311330384484518\n",
            "===========================================================\n",
            "Training loss : 1.1144437789916992\n",
            "Training loss : 1.0981279611587524\n",
            "Training loss : 1.1101429462432861\n",
            "Training loss : 1.0584814548492432\n",
            "Training loss : 1.2126837968826294\n",
            "Training loss : 1.0825493335723877\n",
            "===========================================================\n",
            "Training Acc on Epoch 7: 0.5382783259612113\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 7: 0.5505273902687989\n",
            "===========================================================\n",
            "Training loss : 1.1239625215530396\n",
            "Training loss : 1.1010395288467407\n",
            "Training loss : 1.0330071449279785\n",
            "Training loss : 1.109029769897461\n",
            "Training loss : 1.0490649938583374\n",
            "Training loss : 1.0896528959274292\n",
            "===========================================================\n",
            "Training Acc on Epoch 8: 0.5600544402858115\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 8: 0.5668594760122491\n",
            "===========================================================\n",
            "Training loss : 1.0187970399856567\n",
            "Training loss : 1.0758992433547974\n",
            "Training loss : 1.0560847520828247\n",
            "Training loss : 1.064322590827942\n",
            "Training loss : 1.0700111389160156\n",
            "Training loss : 1.0582014322280884\n",
            "===========================================================\n",
            "Training Acc on Epoch 9: 0.5719632528070773\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 9: 0.5981626403538619\n",
            "===========================================================\n",
            "Training loss : 0.993280291557312\n",
            "Training loss : 1.0703654289245605\n",
            "Training loss : 1.002642035484314\n",
            "Training loss : 1.0266810655593872\n",
            "Training loss : 1.0621709823608398\n",
            "Training loss : 0.9904778003692627\n",
            "===========================================================\n",
            "Training Acc on Epoch 10: 0.5882953385505274\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 10: 0.6076896903708745\n",
            "===========================================================\n",
            "Training loss : 0.9393417835235596\n",
            "Training loss : 1.088771104812622\n",
            "Training loss : 1.0368726253509521\n",
            "Training loss : 1.0030707120895386\n",
            "Training loss : 0.9921861290931702\n",
            "Training loss : 1.0050311088562012\n",
            "===========================================================\n",
            "Training Acc on Epoch 11: 0.60326641714869\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 11: 0.5933991153453556\n",
            "===========================================================\n",
            "Training loss : 1.007567286491394\n",
            "Training loss : 0.9588048458099365\n",
            "Training loss : 1.0602480173110962\n",
            "Training loss : 0.9457972645759583\n",
            "Training loss : 0.9335455894470215\n",
            "Training loss : 0.9746170043945312\n",
            "===========================================================\n",
            "Training Acc on Epoch 12: 0.6195985028921401\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 12: 0.6274242939775434\n",
            "===========================================================\n",
            "Training loss : 0.9987735748291016\n",
            "Training loss : 0.91675865650177\n",
            "Training loss : 0.9355514645576477\n",
            "Training loss : 0.9240764379501343\n",
            "Training loss : 1.058167576789856\n",
            "Training loss : 0.916780948638916\n",
            "===========================================================\n",
            "Training Acc on Epoch 13: 0.6240217761143246\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 13: 0.6420551207893841\n",
            "===========================================================\n",
            "Training loss : 0.9465042948722839\n",
            "Training loss : 0.9755500555038452\n",
            "Training loss : 0.9328450560569763\n",
            "Training loss : 0.8873834013938904\n",
            "Training loss : 0.9048353433609009\n",
            "Training loss : 0.9392890930175781\n",
            "===========================================================\n",
            "Training Acc on Epoch 14: 0.6393331064988091\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 14: 0.6349098332766248\n",
            "===========================================================\n",
            "Training loss : 0.8898435831069946\n",
            "Training loss : 0.924324095249176\n",
            "Training loss : 0.8935049772262573\n",
            "Training loss : 0.9032480120658875\n",
            "Training loss : 0.9774044156074524\n",
            "Training loss : 0.912236213684082\n",
            "===========================================================\n",
            "Training Acc on Epoch 15: 0.6420551207893841\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 15: 0.6702960190541001\n",
            "===========================================================\n",
            "Training loss : 0.8739112019538879\n",
            "Training loss : 0.9593269228935242\n",
            "Training loss : 0.8502564430236816\n",
            "Training loss : 0.8781167268753052\n",
            "Training loss : 0.866290807723999\n",
            "Training loss : 0.9326666593551636\n",
            "===========================================================\n",
            "Training Acc on Epoch 16: 0.6570261993875468\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 16: 0.6607689690370875\n",
            "===========================================================\n",
            "Training loss : 0.9184357523918152\n",
            "Training loss : 0.8423468470573425\n",
            "Training loss : 0.8467164039611816\n",
            "Training loss : 0.8760657906532288\n",
            "Training loss : 0.911813497543335\n",
            "Training loss : 0.8540160059928894\n",
            "===========================================================\n",
            "Training Acc on Epoch 17: 0.6570261993875468\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 17: 0.6485199047294998\n",
            "===========================================================\n",
            "Training loss : 0.9004194736480713\n",
            "Training loss : 0.8931382298469543\n",
            "Training loss : 0.8559337854385376\n",
            "Training loss : 0.8117391467094421\n",
            "Training loss : 0.8724143505096436\n",
            "Training loss : 0.804966926574707\n",
            "===========================================================\n",
            "Training Acc on Epoch 18: 0.6689350119088125\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 18: 0.6886696155154814\n",
            "===========================================================\n",
            "Training loss : 0.8095768094062805\n",
            "Training loss : 0.8348819613456726\n",
            "Training loss : 0.7674697041511536\n",
            "Training loss : 0.7846102118492126\n",
            "Training loss : 0.8512828350067139\n",
            "Training loss : 0.7853000164031982\n",
            "===========================================================\n",
            "Training Acc on Epoch 19: 0.698536917318816\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 19: 0.7124872405580129\n",
            "===========================================================\n",
            "Training loss : 0.7434589266777039\n",
            "Training loss : 0.8292175531387329\n",
            "Training loss : 0.7957331538200378\n",
            "Training loss : 0.7563813924789429\n",
            "Training loss : 0.8265121579170227\n",
            "Training loss : 0.7438620328903198\n",
            "===========================================================\n",
            "Training Acc on Epoch 20: 0.7169105137801973\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 20: 0.6961551548145628\n",
            "===========================================================\n",
            "Training loss : 0.8287175893783569\n",
            "Training loss : 0.7281380295753479\n",
            "Training loss : 0.8416711091995239\n",
            "Training loss : 0.7015407085418701\n",
            "Training loss : 0.7754392027854919\n",
            "Training loss : 0.7991112470626831\n",
            "===========================================================\n",
            "Training Acc on Epoch 21: 0.7087444709084723\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 21: 0.7434501531133039\n",
            "===========================================================\n",
            "Training loss : 0.7563281655311584\n",
            "Training loss : 0.7682976126670837\n",
            "Training loss : 0.7103814482688904\n",
            "Training loss : 0.6902633309364319\n",
            "Training loss : 0.7279477715492249\n",
            "Training loss : 0.6781360507011414\n",
            "===========================================================\n",
            "Training Acc on Epoch 22: 0.73188159237836\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 22: 0.7591017352841103\n",
            "===========================================================\n",
            "Training loss : 0.6838068962097168\n",
            "Training loss : 0.6857248544692993\n",
            "Training loss : 0.6608150005340576\n",
            "Training loss : 0.7691317796707153\n",
            "Training loss : 0.6492829918861389\n",
            "Training loss : 0.7317932844161987\n",
            "===========================================================\n",
            "Training Acc on Epoch 23: 0.7533174549166383\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 23: 0.7322218441646818\n",
            "===========================================================\n",
            "Training loss : 0.6906119585037231\n",
            "Training loss : 0.6233782768249512\n",
            "Training loss : 0.7073900103569031\n",
            "Training loss : 0.6526005268096924\n",
            "Training loss : 0.6843268871307373\n",
            "Training loss : 0.6338023543357849\n",
            "===========================================================\n",
            "Training Acc on Epoch 24: 0.7665872745831915\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 24: 0.765226267437904\n",
            "===========================================================\n",
            "Training loss : 0.6517526507377625\n",
            "Training loss : 0.5915204882621765\n",
            "Training loss : 0.6736559271812439\n",
            "Training loss : 0.6440218687057495\n",
            "Training loss : 0.6627101302146912\n",
            "Training loss : 0.6998835206031799\n",
            "===========================================================\n",
            "Training Acc on Epoch 25: 0.7689690370874447\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 25: 0.7958489282068731\n",
            "===========================================================\n",
            "Training loss : 0.6205571293830872\n",
            "Training loss : 0.5928762555122375\n",
            "Training loss : 0.6342841982841492\n",
            "Training loss : 0.5864264965057373\n",
            "Training loss : 0.5724771022796631\n",
            "Training loss : 0.5388762950897217\n",
            "===========================================================\n",
            "Training Acc on Epoch 26: 0.8029942157196325\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 26: 0.776794828172848\n",
            "===========================================================\n",
            "Training loss : 0.6610366702079773\n",
            "Training loss : 0.6001570820808411\n",
            "Training loss : 0.6213288903236389\n",
            "Training loss : 0.6167312264442444\n",
            "Training loss : 0.6394380331039429\n",
            "Training loss : 0.5941231846809387\n",
            "===========================================================\n",
            "Training Acc on Epoch 27: 0.7801973460360667\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 27: 0.7887036406941137\n",
            "===========================================================\n",
            "Training loss : 0.5649811029434204\n",
            "Training loss : 0.5134483575820923\n",
            "Training loss : 0.650497317314148\n",
            "Training loss : 0.6232228875160217\n",
            "Training loss : 0.6003866195678711\n",
            "Training loss : 0.5467186570167542\n",
            "===========================================================\n",
            "Training Acc on Epoch 28: 0.8006124532153793\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 28: 0.7921061585573325\n",
            "===========================================================\n",
            "Training loss : 0.5682647824287415\n",
            "Training loss : 0.45799511671066284\n",
            "Training loss : 0.6218577027320862\n",
            "Training loss : 0.5969250202178955\n",
            "Training loss : 0.6344083547592163\n",
            "Training loss : 0.5302168726921082\n",
            "===========================================================\n",
            "Training Acc on Epoch 29: 0.8012929567880231\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 29: 0.8387206532834297\n",
            "===========================================================\n",
            "Training loss : 0.48914793133735657\n",
            "Training loss : 0.6019246578216553\n",
            "Training loss : 0.5093574523925781\n",
            "Training loss : 0.4778106212615967\n",
            "Training loss : 0.5551971197128296\n",
            "Training loss : 0.5005142688751221\n",
            "===========================================================\n",
            "Training Acc on Epoch 30: 0.8305546104117046\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 30: 0.8302143586253827\n",
            "===========================================================\n",
            "Training loss : 0.5050873160362244\n",
            "Training loss : 0.46881502866744995\n",
            "Training loss : 0.44182565808296204\n",
            "Training loss : 0.5797418355941772\n",
            "Training loss : 0.4675273299217224\n",
            "Training loss : 0.48624634742736816\n",
            "===========================================================\n",
            "Training Acc on Epoch 31: 0.8445049336509016\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 31: 0.8428036747192923\n",
            "===========================================================\n",
            "Training loss : 0.47104495763778687\n",
            "Training loss : 0.5276472568511963\n",
            "Training loss : 0.4786463975906372\n",
            "Training loss : 0.4777483642101288\n",
            "Training loss : 0.5354835391044617\n",
            "Training loss : 0.41939860582351685\n",
            "===========================================================\n",
            "Training Acc on Epoch 32: 0.8353181354202109\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 32: 0.829533855052739\n",
            "===========================================================\n",
            "Training loss : 0.5100207924842834\n",
            "Training loss : 0.37751874327659607\n",
            "Training loss : 0.5880089402198792\n",
            "Training loss : 0.4855180084705353\n",
            "Training loss : 0.5023041367530823\n",
            "Training loss : 0.5144269466400146\n",
            "===========================================================\n",
            "Training Acc on Epoch 33: 0.8308948621980266\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 33: 0.8496087104457298\n",
            "===========================================================\n",
            "Training loss : 0.4280393421649933\n",
            "Training loss : 0.43340837955474854\n",
            "Training loss : 0.5084152817726135\n",
            "Training loss : 0.5306780934333801\n",
            "Training loss : 0.39976465702056885\n",
            "Training loss : 0.5009267330169678\n",
            "===========================================================\n",
            "Training Acc on Epoch 34: 0.8322558693433141\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 34: 0.863218781898605\n",
            "===========================================================\n",
            "Training loss : 0.41075584292411804\n",
            "Training loss : 0.4249171316623688\n",
            "Training loss : 0.3656339645385742\n",
            "Training loss : 0.4528430700302124\n",
            "Training loss : 0.390572726726532\n",
            "Training loss : 0.4335203766822815\n",
            "===========================================================\n",
            "Training Acc on Epoch 35: 0.8720653283429738\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 35: 0.8975842123171147\n",
            "===========================================================\n",
            "Training loss : 0.37692201137542725\n",
            "Training loss : 0.34530603885650635\n",
            "Training loss : 0.36242952942848206\n",
            "Training loss : 0.3969994783401489\n",
            "Training loss : 0.35518890619277954\n",
            "Training loss : 0.35165780782699585\n",
            "===========================================================\n",
            "Training Acc on Epoch 36: 0.8958829533855053\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 36: 0.9060905069751616\n",
            "===========================================================\n",
            "Training loss : 0.33080726861953735\n",
            "Training loss : 0.2986125349998474\n",
            "Training loss : 0.36338019371032715\n",
            "Training loss : 0.3040367364883423\n",
            "Training loss : 0.3346061408519745\n",
            "Training loss : 0.3211401700973511\n",
            "===========================================================\n",
            "Training Acc on Epoch 37: 0.9054100034025179\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 37: 0.9254848587955087\n",
            "===========================================================\n",
            "Training loss : 0.30168503522872925\n",
            "Training loss : 0.28140124678611755\n",
            "Training loss : 0.31478458642959595\n",
            "Training loss : 0.32048216462135315\n",
            "Training loss : 0.3028605282306671\n",
            "Training loss : 0.2955745756626129\n",
            "===========================================================\n",
            "Training Acc on Epoch 38: 0.9190200748553929\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 38: 0.9339911534535557\n",
            "===========================================================\n",
            "Training loss : 0.28063255548477173\n",
            "Training loss : 0.28727617859840393\n",
            "Training loss : 0.25440460443496704\n",
            "Training loss : 0.2904188930988312\n",
            "Training loss : 0.24049009382724762\n",
            "Training loss : 0.26886630058288574\n",
            "===========================================================\n",
            "Training Acc on Epoch 39: 0.93297039809459\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 39: 0.9380741748894181\n",
            "===========================================================\n",
            "Training loss : 0.24783438444137573\n",
            "Training loss : 0.24822098016738892\n",
            "Training loss : 0.2652530074119568\n",
            "Training loss : 0.3125569224357605\n",
            "Training loss : 0.2708698511123657\n",
            "Training loss : 0.2889389097690582\n",
            "===========================================================\n",
            "Training Acc on Epoch 40: 0.921742089145968\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 40: 0.9285471248724055\n",
            "===========================================================\n",
            "Training loss : 0.2571604549884796\n",
            "Training loss : 0.27488020062446594\n",
            "Training loss : 0.23516200482845306\n",
            "Training loss : 0.2150786817073822\n",
            "Training loss : 0.2504798173904419\n",
            "Training loss : 0.24734194576740265\n",
            "===========================================================\n",
            "Training Acc on Epoch 41: 0.9360326641714869\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 41: 0.9428376998979244\n",
            "===========================================================\n",
            "Training loss : 0.22696638107299805\n",
            "Training loss : 0.23258760571479797\n",
            "Training loss : 0.2546069920063019\n",
            "Training loss : 0.22847269475460052\n",
            "Training loss : 0.21581080555915833\n",
            "Training loss : 0.19563014805316925\n",
            "===========================================================\n",
            "Training Acc on Epoch 42: 0.9448792106158558\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 42: 0.9537257570602246\n",
            "===========================================================\n",
            "Training loss : 0.2085867077112198\n",
            "Training loss : 0.19357895851135254\n",
            "Training loss : 0.21155862510204315\n",
            "Training loss : 0.237295001745224\n",
            "Training loss : 0.17290431261062622\n",
            "Training loss : 0.24927590787410736\n",
            "===========================================================\n",
            "Training Acc on Epoch 43: 0.9506634909833277\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 43: 0.9550867642055121\n",
            "===========================================================\n",
            "Training loss : 0.19205953180789948\n",
            "Training loss : 0.17931465804576874\n",
            "Training loss : 0.23091229796409607\n",
            "Training loss : 0.21330060064792633\n",
            "Training loss : 0.21658377349376678\n",
            "Training loss : 0.18259887397289276\n",
            "===========================================================\n",
            "Training Acc on Epoch 44: 0.9513439945559714\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 44: 0.9486219802653963\n",
            "===========================================================\n",
            "Training loss : 0.22103749215602875\n",
            "Training loss : 0.2084140181541443\n",
            "Training loss : 0.15377189218997955\n",
            "Training loss : 0.18739624321460724\n",
            "Training loss : 0.18009673058986664\n",
            "Training loss : 0.20118315517902374\n",
            "===========================================================\n",
            "Training Acc on Epoch 45: 0.9544062606328684\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 45: 0.9591697856413747\n",
            "===========================================================\n",
            "Training loss : 0.20693586766719818\n",
            "Training loss : 0.16762793064117432\n",
            "Training loss : 0.17145055532455444\n",
            "Training loss : 0.1619485467672348\n",
            "Training loss : 0.16514286398887634\n",
            "Training loss : 0.16738319396972656\n",
            "===========================================================\n",
            "Training Acc on Epoch 46: 0.9625723035045934\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 46: 0.9785641374617217\n",
            "===========================================================\n",
            "Training loss : 0.1416156142950058\n",
            "Training loss : 0.15604031085968018\n",
            "Training loss : 0.16569969058036804\n",
            "Training loss : 0.12786054611206055\n",
            "Training loss : 0.1712838113307953\n",
            "Training loss : 0.14813807606697083\n",
            "===========================================================\n",
            "Training Acc on Epoch 47: 0.969377339231031\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 47: 0.9724396053079278\n",
            "===========================================================\n",
            "Training loss : 0.169416144490242\n",
            "Training loss : 0.1430474817752838\n",
            "Training loss : 0.14393188059329987\n",
            "Training loss : 0.1049923375248909\n",
            "Training loss : 0.12101394683122635\n",
            "Training loss : 0.13544179499149323\n",
            "===========================================================\n",
            "Training Acc on Epoch 48: 0.9744811160258592\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 48: 0.977883633889078\n",
            "===========================================================\n",
            "Training loss : 0.14169524610042572\n",
            "Training loss : 0.12031982094049454\n",
            "Training loss : 0.12151218205690384\n",
            "Training loss : 0.11264511197805405\n",
            "Training loss : 0.11813864856958389\n",
            "Training loss : 0.09432820230722427\n",
            "===========================================================\n",
            "Training Acc on Epoch 49: 0.9819666553249404\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 49: 0.9843484178291936\n",
            "===========================================================\n",
            "Training loss : 0.10211861878633499\n",
            "Training loss : 0.10237043350934982\n",
            "Training loss : 0.1135408878326416\n",
            "Training loss : 0.10591321438550949\n",
            "Training loss : 0.10095483809709549\n",
            "Training loss : 0.07654079794883728\n",
            "===========================================================\n",
            "Training Acc on Epoch 50: 0.9846886696155155\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 50: 0.9874106839060905\n",
            "===========================================================\n",
            "Training loss : 0.09357338398694992\n",
            "Training loss : 0.10333889722824097\n",
            "Training loss : 0.08250501751899719\n",
            "Training loss : 0.08756831288337708\n",
            "Training loss : 0.08365751802921295\n",
            "Training loss : 0.10398268699645996\n",
            "===========================================================\n",
            "Training Acc on Epoch 51: 0.9880911874787343\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 51: 0.9894521946240218\n",
            "===========================================================\n",
            "Training loss : 0.10149732232093811\n",
            "Training loss : 0.08658662438392639\n",
            "Training loss : 0.07714052498340607\n",
            "Training loss : 0.08443013578653336\n",
            "Training loss : 0.0672914981842041\n",
            "Training loss : 0.06756672263145447\n",
            "===========================================================\n",
            "Training Acc on Epoch 52: 0.9901326981966655\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 52: 0.991493705341953\n",
            "===========================================================\n",
            "Training loss : 0.06804584711790085\n",
            "Training loss : 0.056675706058740616\n",
            "Training loss : 0.07472884654998779\n",
            "Training loss : 0.08134924620389938\n",
            "Training loss : 0.0691659227013588\n",
            "Training loss : 0.07738887518644333\n",
            "===========================================================\n",
            "Training Acc on Epoch 53: 0.991493705341953\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 53: 0.9928547124872406\n",
            "===========================================================\n",
            "Training loss : 0.06685817986726761\n",
            "Training loss : 0.06755626946687698\n",
            "Training loss : 0.0801468938589096\n",
            "Training loss : 0.09534100443124771\n",
            "Training loss : 0.059496909379959106\n",
            "Training loss : 0.09887678176164627\n",
            "===========================================================\n",
            "Training Acc on Epoch 54: 0.9897924464103437\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 54: 0.9928547124872406\n",
            "===========================================================\n",
            "Training loss : 0.06339892745018005\n",
            "Training loss : 0.07880482822656631\n",
            "Training loss : 0.05353977903723717\n",
            "Training loss : 0.06245645508170128\n",
            "Training loss : 0.05651605874300003\n",
            "Training loss : 0.10507582873106003\n",
            "===========================================================\n",
            "Training Acc on Epoch 55: 0.9908132017693093\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 55: 0.9959169785641374\n",
            "===========================================================\n",
            "Training loss : 0.06561514735221863\n",
            "Training loss : 0.06680670380592346\n",
            "Training loss : 0.0487155020236969\n",
            "Training loss : 0.09200503677129745\n",
            "Training loss : 0.06958989799022675\n",
            "Training loss : 0.08719675987958908\n",
            "===========================================================\n",
            "Training Acc on Epoch 56: 0.9908132017693093\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 56: 0.9850289214018374\n",
            "===========================================================\n",
            "Training loss : 0.09841035306453705\n",
            "Training loss : 0.08360233157873154\n",
            "Training loss : 0.06362882256507874\n",
            "Training loss : 0.12405738979578018\n",
            "Training loss : 0.11779266595840454\n",
            "Training loss : 0.06052005663514137\n",
            "===========================================================\n",
            "Training Acc on Epoch 57: 0.9792446410343655\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 57: 0.9853691731881592\n",
            "===========================================================\n",
            "Training loss : 0.07835600525140762\n",
            "Training loss : 0.10185553878545761\n",
            "Training loss : 0.08616968989372253\n",
            "Training loss : 0.08490452915430069\n",
            "Training loss : 0.10616695880889893\n",
            "Training loss : 0.07826327532529831\n",
            "===========================================================\n",
            "Training Acc on Epoch 58: 0.9840081660428718\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 58: 0.99455597141885\n",
            "===========================================================\n",
            "Training loss : 0.05174536630511284\n",
            "Training loss : 0.08079160749912262\n",
            "Training loss : 0.04268505796790123\n",
            "Training loss : 0.08347900211811066\n",
            "Training loss : 0.062407661229372025\n",
            "Training loss : 0.04690613970160484\n",
            "===========================================================\n",
            "Training Acc on Epoch 59: 0.9935352160598843\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 59: 0.9894521946240218\n",
            "===========================================================\n",
            "Training loss : 0.06474640220403671\n",
            "Training loss : 0.035327278077602386\n",
            "Training loss : 0.05049281567335129\n",
            "Training loss : 0.046979472041130066\n",
            "Training loss : 0.04438038915395737\n",
            "Training loss : 0.046792205423116684\n",
            "===========================================================\n",
            "Training Acc on Epoch 60: 0.9952364749914937\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 60: 0.9965974821367812\n",
            "===========================================================\n",
            "Training loss : 0.039133958518505096\n",
            "Training loss : 0.040588535368442535\n",
            "Training loss : 0.036326583474874496\n",
            "Training loss : 0.045623041689395905\n",
            "Training loss : 0.036773018538951874\n",
            "Training loss : 0.03187812492251396\n",
            "===========================================================\n",
            "Training Acc on Epoch 61: 0.9969377339231031\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 61: 0.9982987410683906\n",
            "===========================================================\n",
            "Training loss : 0.036839667707681656\n",
            "Training loss : 0.03576892614364624\n",
            "Training loss : 0.034163784235715866\n",
            "Training loss : 0.036246661096811295\n",
            "Training loss : 0.034759584814310074\n",
            "Training loss : 0.02624807320535183\n",
            "===========================================================\n",
            "Training Acc on Epoch 62: 0.9979584892820688\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 62: 0.9986389928547125\n",
            "===========================================================\n",
            "Training loss : 0.03342529386281967\n",
            "Training loss : 0.02897312305867672\n",
            "Training loss : 0.024218181148171425\n",
            "Training loss : 0.03549541160464287\n",
            "Training loss : 0.034149471670389175\n",
            "Training loss : 0.04440813884139061\n",
            "===========================================================\n",
            "Training Acc on Epoch 63: 0.9976182374957469\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 63: 0.9989792446410344\n",
            "===========================================================\n",
            "Training loss : 0.028529589995741844\n",
            "Training loss : 0.03039482794702053\n",
            "Training loss : 0.03191352263092995\n",
            "Training loss : 0.02640695683658123\n",
            "Training loss : 0.03199385106563568\n",
            "Training loss : 0.0334782712161541\n",
            "===========================================================\n",
            "Training Acc on Epoch 64: 0.9982987410683906\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 64: 0.9986389928547125\n",
            "===========================================================\n",
            "Training loss : 0.023478901013731956\n",
            "Training loss : 0.024067940190434456\n",
            "Training loss : 0.032553769648075104\n",
            "Training loss : 0.021064404398202896\n",
            "Training loss : 0.031368937343358994\n",
            "Training loss : 0.0272053312510252\n",
            "===========================================================\n",
            "Training Acc on Epoch 65: 0.9982987410683906\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 65: 0.9989792446410344\n",
            "===========================================================\n",
            "Training loss : 0.019728954881429672\n",
            "Training loss : 0.02174227312207222\n",
            "Training loss : 0.033472154289484024\n",
            "Training loss : 0.02057131752371788\n",
            "Training loss : 0.02841046266257763\n",
            "Training loss : 0.022191207855939865\n",
            "===========================================================\n",
            "Training Acc on Epoch 66: 0.9986389928547125\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 66: 0.9979584892820688\n",
            "===========================================================\n",
            "Training loss : 0.018387068063020706\n",
            "Training loss : 0.02135867439210415\n",
            "Training loss : 0.022476185113191605\n",
            "Training loss : 0.021064486354589462\n",
            "Training loss : 0.028209781274199486\n",
            "Training loss : 0.02605215646326542\n",
            "===========================================================\n",
            "Training Acc on Epoch 67: 0.9979584892820688\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 67: 0.9982987410683906\n",
            "===========================================================\n",
            "Training loss : 0.02572399564087391\n",
            "Training loss : 0.019014468416571617\n",
            "Training loss : 0.019135894253849983\n",
            "Training loss : 0.020206835120916367\n",
            "Training loss : 0.0258612260222435\n",
            "Training loss : 0.018310843035578728\n",
            "===========================================================\n",
            "Training Acc on Epoch 68: 0.9979584892820688\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 68: 0.9989792446410344\n",
            "===========================================================\n",
            "Training loss : 0.016604477539658546\n",
            "Training loss : 0.020343897864222527\n",
            "Training loss : 0.01632290706038475\n",
            "Training loss : 0.020270278677344322\n",
            "Training loss : 0.01645757257938385\n",
            "Training loss : 0.024959765374660492\n",
            "===========================================================\n",
            "Training Acc on Epoch 69: 0.9986389928547125\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 69: 0.9989792446410344\n",
            "===========================================================\n",
            "Training loss : 0.01798374578356743\n",
            "Training loss : 0.01574196293950081\n",
            "Training loss : 0.01674453727900982\n",
            "Training loss : 0.025858676061034203\n",
            "Training loss : 0.01795242168009281\n",
            "Training loss : 0.0210327859967947\n",
            "===========================================================\n",
            "Training Acc on Epoch 70: 0.9972779857094249\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 70: 0.9993194964273563\n",
            "===========================================================\n",
            "Training loss : 0.014139280654489994\n",
            "Training loss : 0.019026724621653557\n",
            "Training loss : 0.017101289704442024\n",
            "Training loss : 0.02231038361787796\n",
            "Training loss : 0.012245790101587772\n",
            "Training loss : 0.01702590472996235\n",
            "===========================================================\n",
            "Training Acc on Epoch 71: 0.9993194964273563\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 71: 0.9989792446410344\n",
            "===========================================================\n",
            "Training loss : 0.011894539929926395\n",
            "Training loss : 0.013881133869290352\n",
            "Training loss : 0.01573583297431469\n",
            "Training loss : 0.014457411132752895\n",
            "Training loss : 0.019172223284840584\n",
            "Training loss : 0.013374486938118935\n",
            "===========================================================\n",
            "Training Acc on Epoch 72: 0.9986389928547125\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 72: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.014187604188919067\n",
            "Training loss : 0.012247883714735508\n",
            "Training loss : 0.014579225331544876\n",
            "Training loss : 0.015967892482876778\n",
            "Training loss : 0.013343780301511288\n",
            "Training loss : 0.011294110678136349\n",
            "===========================================================\n",
            "Training Acc on Epoch 73: 0.9993194964273563\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 73: 0.9993194964273563\n",
            "===========================================================\n",
            "Training loss : 0.009749856777489185\n",
            "Training loss : 0.009686104021966457\n",
            "Training loss : 0.013453671708703041\n",
            "Training loss : 0.012032371945679188\n",
            "Training loss : 0.01837065815925598\n",
            "Training loss : 0.012325516901910305\n",
            "===========================================================\n",
            "Training Acc on Epoch 74: 0.9993194964273563\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 74: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.012487085536122322\n",
            "Training loss : 0.011963984929025173\n",
            "Training loss : 0.009665094316005707\n",
            "Training loss : 0.011052137240767479\n",
            "Training loss : 0.012556909583508968\n",
            "Training loss : 0.009845378808677197\n",
            "===========================================================\n",
            "Training Acc on Epoch 75: 0.9993194964273563\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 75: 0.9993194964273563\n",
            "===========================================================\n",
            "Training loss : 0.009791120886802673\n",
            "Training loss : 0.010320739820599556\n",
            "Training loss : 0.010636236518621445\n",
            "Training loss : 0.01044983696192503\n",
            "Training loss : 0.013363976031541824\n",
            "Training loss : 0.01112376619130373\n",
            "===========================================================\n",
            "Training Acc on Epoch 76: 0.9989792446410344\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 76: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.015009595081210136\n",
            "Training loss : 0.008535160683095455\n",
            "Training loss : 0.013195794075727463\n",
            "Training loss : 0.008378450758755207\n",
            "Training loss : 0.009213246405124664\n",
            "Training loss : 0.008973362855613232\n",
            "===========================================================\n",
            "Training Acc on Epoch 77: 0.9989792446410344\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 77: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.008800684474408627\n",
            "Training loss : 0.008050079457461834\n",
            "Training loss : 0.012353076599538326\n",
            "Training loss : 0.007681707851588726\n",
            "Training loss : 0.01207957323640585\n",
            "Training loss : 0.008447973057627678\n",
            "===========================================================\n",
            "Training Acc on Epoch 78: 0.9993194964273563\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 78: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.008775163441896439\n",
            "Training loss : 0.007734792772680521\n",
            "Training loss : 0.010054833255708218\n",
            "Training loss : 0.012535820715129375\n",
            "Training loss : 0.007047408260405064\n",
            "Training loss : 0.009576771408319473\n",
            "===========================================================\n",
            "Training Acc on Epoch 79: 0.9996597482136781\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 79: 0.9993194964273563\n",
            "===========================================================\n",
            "Training loss : 0.010083705186843872\n",
            "Training loss : 0.007422544062137604\n",
            "Training loss : 0.008686396293342113\n",
            "Training loss : 0.009037556126713753\n",
            "Training loss : 0.008261527866125107\n",
            "Training loss : 0.009173339232802391\n",
            "===========================================================\n",
            "Training Acc on Epoch 80: 0.9989792446410344\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 80: 0.9993194964273563\n",
            "===========================================================\n",
            "Training loss : 0.008049719035625458\n",
            "Training loss : 0.007918009534478188\n",
            "Training loss : 0.008101177401840687\n",
            "Training loss : 0.00569023285061121\n",
            "Training loss : 0.008155353367328644\n",
            "Training loss : 0.011999822221696377\n",
            "===========================================================\n",
            "Training Acc on Epoch 81: 0.9996597482136781\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 81: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.0065101818181574345\n",
            "Training loss : 0.00872219167649746\n",
            "Training loss : 0.011946399696171284\n",
            "Training loss : 0.0060782465152442455\n",
            "Training loss : 0.008040366694331169\n",
            "Training loss : 0.011329892091453075\n",
            "===========================================================\n",
            "Training Acc on Epoch 82: 0.9993194964273563\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 82: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.008049281314015388\n",
            "Training loss : 0.007294087205082178\n",
            "Training loss : 0.008082596585154533\n",
            "Training loss : 0.009422320872545242\n",
            "Training loss : 0.005127169191837311\n",
            "Training loss : 0.011310840025544167\n",
            "===========================================================\n",
            "Training Acc on Epoch 83: 0.9993194964273563\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 83: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.009142897091805935\n",
            "Training loss : 0.008687986060976982\n",
            "Training loss : 0.0073540182784199715\n",
            "Training loss : 0.008115341886878014\n",
            "Training loss : 0.011008864268660545\n",
            "Training loss : 0.00627201097086072\n",
            "===========================================================\n",
            "Training Acc on Epoch 84: 0.9996597482136781\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 84: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.005798347294330597\n",
            "Training loss : 0.008727557957172394\n",
            "Training loss : 0.007308273110538721\n",
            "Training loss : 0.011049467138946056\n",
            "Training loss : 0.007698575966060162\n",
            "Training loss : 0.008962930180132389\n",
            "===========================================================\n",
            "Training Acc on Epoch 85: 0.9996597482136781\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 85: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.0054509700275957584\n",
            "Training loss : 0.008074880577623844\n",
            "Training loss : 0.006970925256609917\n",
            "Training loss : 0.008305644616484642\n",
            "Training loss : 0.008799211122095585\n",
            "Training loss : 0.005455381702631712\n",
            "===========================================================\n",
            "Training Acc on Epoch 86: 0.9996597482136781\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 86: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.010537365451455116\n",
            "Training loss : 0.0054435147903859615\n",
            "Training loss : 0.00504903681576252\n",
            "Training loss : 0.008831217885017395\n",
            "Training loss : 0.005663989577442408\n",
            "Training loss : 0.00529084075242281\n",
            "===========================================================\n",
            "Training Acc on Epoch 87: 0.9996597482136781\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 87: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.0064201136119663715\n",
            "Training loss : 0.006307469680905342\n",
            "Training loss : 0.0058960397727787495\n",
            "Training loss : 0.005587147548794746\n",
            "Training loss : 0.0066324383951723576\n",
            "Training loss : 0.00988831091672182\n",
            "===========================================================\n",
            "Training Acc on Epoch 88: 0.9996597482136781\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 88: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.005803300533443689\n",
            "Training loss : 0.007031523622572422\n",
            "Training loss : 0.005837887991219759\n",
            "Training loss : 0.00995565950870514\n",
            "Training loss : 0.004415178671479225\n",
            "Training loss : 0.008644836023449898\n",
            "===========================================================\n",
            "Training Acc on Epoch 89: 0.9996597482136781\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 89: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.005927370861172676\n",
            "Training loss : 0.006443466991186142\n",
            "Training loss : 0.005606412887573242\n",
            "Training loss : 0.0050049955025315285\n",
            "Training loss : 0.006170536857098341\n",
            "Training loss : 0.008852215483784676\n",
            "===========================================================\n",
            "Training Acc on Epoch 90: 0.9993194964273563\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 90: 0.9993194964273563\n",
            "===========================================================\n",
            "Training loss : 0.005534818395972252\n",
            "Training loss : 0.004585469141602516\n",
            "Training loss : 0.008023244328796864\n",
            "Training loss : 0.004326443653553724\n",
            "Training loss : 0.006721739657223225\n",
            "Training loss : 0.005328007508069277\n",
            "===========================================================\n",
            "Training Acc on Epoch 91: 0.9993194964273563\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 91: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.004940649960190058\n",
            "Training loss : 0.004507620353251696\n",
            "Training loss : 0.004227519501000643\n",
            "Training loss : 0.003952700179070234\n",
            "Training loss : 0.005763264838606119\n",
            "Training loss : 0.007517017424106598\n",
            "===========================================================\n",
            "Training Acc on Epoch 92: 0.9996597482136781\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 92: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.004473029635846615\n",
            "Training loss : 0.006013595499098301\n",
            "Training loss : 0.003862787736579776\n",
            "Training loss : 0.008782422170042992\n",
            "Training loss : 0.0047033317387104034\n",
            "Training loss : 0.004109896253794432\n",
            "===========================================================\n",
            "Training Acc on Epoch 93: 0.9993194964273563\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 93: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.0037591643631458282\n",
            "Training loss : 0.0057320198975503445\n",
            "Training loss : 0.0034775712992995977\n",
            "Training loss : 0.009786192327737808\n",
            "Training loss : 0.004321727901697159\n",
            "Training loss : 0.004227569326758385\n",
            "===========================================================\n",
            "Training Acc on Epoch 94: 0.9996597482136781\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 94: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.004461212549358606\n",
            "Training loss : 0.004648137837648392\n",
            "Training loss : 0.004581273067742586\n",
            "Training loss : 0.00830018986016512\n",
            "Training loss : 0.004218918737024069\n",
            "Training loss : 0.004788385704159737\n",
            "===========================================================\n",
            "Training Acc on Epoch 95: 0.9996597482136781\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 95: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.0051095495000481606\n",
            "Training loss : 0.008015432395040989\n",
            "Training loss : 0.003867098828777671\n",
            "Training loss : 0.004900123458355665\n",
            "Training loss : 0.004336679354310036\n",
            "Training loss : 0.003835948184132576\n",
            "===========================================================\n",
            "Training Acc on Epoch 96: 0.9996597482136781\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 96: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.006514559965580702\n",
            "Training loss : 0.004531011451035738\n",
            "Training loss : 0.004826028365641832\n",
            "Training loss : 0.004645099863409996\n",
            "Training loss : 0.010232099331915379\n",
            "Training loss : 0.004029444884508848\n",
            "===========================================================\n",
            "Training Acc on Epoch 97: 0.9993194964273563\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 97: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.006574492435902357\n",
            "Training loss : 0.004810771439224482\n",
            "Training loss : 0.0033760026562958956\n",
            "Training loss : 0.0034426026977598667\n",
            "Training loss : 0.0053105344995856285\n",
            "Training loss : 0.010382765904068947\n",
            "===========================================================\n",
            "Training Acc on Epoch 98: 0.9996597482136781\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 98: 0.9996597482136781\n",
            "===========================================================\n",
            "Training loss : 0.005398011766374111\n",
            "Training loss : 0.0038376329466700554\n",
            "Training loss : 0.005504454020410776\n",
            "Training loss : 0.005039690062403679\n",
            "Training loss : 0.011761671863496304\n",
            "Training loss : 0.00664752721786499\n",
            "===========================================================\n",
            "Training Acc on Epoch 99: 0.9993194964273563\n",
            "===========================================================\n",
            "===========================================================\n",
            "Test Acc on Epoch 99: 0.9996597482136781\n",
            "===========================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Acc on Epoch 99: 0.9996597482136781\n"
      ],
      "metadata": {
        "id": "gL4hCPhvvUjL"
      }
    }
  ]
}