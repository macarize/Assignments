{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9930095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb15e3c4",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "Here, your features X follow some 2D multivariate Gaussian distribution with mean D.\n",
    "\n",
    "Try PCA where the code dim l = 2 & visualize the PC vectors with your features. How do they look like? What can you say about this Gaussian distribution? Discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa7efb3",
   "metadata": {},
   "source": [
    "## 1.1 Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e718338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_value = np.loadtxt(\"f_value.txt\", delimiter=\",\") #dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f_value.shape) #Dimension of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b57f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot data\n",
    "plt.scatter(f_value[:, 0], f_value[:, 1], s=1)\n",
    "plt.axis(\"equal\")\n",
    "# plt.xlim(-10, 10)\n",
    "# plt.ylim(-10, 10)\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c364054",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec83b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Axis-aware mean\n",
    "def mean(x, axis=None):\n",
    "    if axis is not None:\n",
    "        axis_len = x.shape[0]\n",
    "        mean = np.array([])\n",
    "        axis_sum = np.sum(x, axis=axis)\n",
    "        axis_mean = axis_sum / axis_len\n",
    "        mean = np.append(mean, axis_mean)\n",
    "        return mean\n",
    "    else:\n",
    "        return x.sum()/x.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e8e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#std implementation from scratch\n",
    "def std(x, axis=None):\n",
    "    if axis is None:\n",
    "        x_mean = mean(x)\n",
    "        return np.sqrt(np.sum((x-x_mean)**2)/(x.size-1))\n",
    "    else:\n",
    "        x_mean = mean(x, axis_=axis)\n",
    "        return np.sqrt(np.sum((x- x_mean)**2, axis=axis)/(x.shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de23aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple normalization (no sign change)\n",
    "data = (f_value - np.mean(f_value)) / (np.std(f_value, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeab415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Axis-aware L2 normalization implementation (sign change)\n",
    "\n",
    "def normalize_(x, axis=None):\n",
    "    min = np.amin(x)\n",
    "    x += min\n",
    "    if axis is not None:\n",
    "        l2_norm = np.sqrt(np.sum(x * x, axis=axis))\n",
    "        return x / l2_norm\n",
    "    else:\n",
    "        l2_norm = np.sqrt(np.sum(x * x))\n",
    "        return x / l2_norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a7c813",
   "metadata": {},
   "source": [
    "## 1.2 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e2049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD method\n",
    "# data: [num_data, feature dimension]\n",
    "def pca(data, n_components=2,method='svd'):\n",
    "    vals, vecs = None, None\n",
    "    if method == 'svd':\n",
    "        #Caclulating SVD\n",
    "        U,S,Vt = np.linalg.svd(data, full_matrices=False, compute_uv=True)\n",
    "        vals = np.square(S) / (data.shape[0] - 1)\n",
    "        vecs = Vt[:n_components]\n",
    "    else:\n",
    "        # eigendecomposition method\n",
    "        cov = np.dot(data.T, data)\n",
    "        vals, vecs = np.linalg.eig(cov)\n",
    "        vecs = vecs[:n_components]\n",
    "    \"\"\"\n",
    "    print(f'vals:{vals}')\n",
    "    print(f'vecs:{vecs}')\n",
    "    \"\"\"\n",
    "    return vals, vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cc475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, vecs = pca(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc0ee89",
   "metadata": {},
   "source": [
    "## 1.3 Visualize PC vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0463ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(f_value[:, 0], f_value[:, 1], s=1)\n",
    "plt.axis(\"equal\")\n",
    "# plt.xlim(-10, 10)\n",
    "# plt.ylim(-10, 10)\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "origin_pt = np.array([0,0])\n",
    "plt.quiver(*origin_pt, vecs[0,0], vecs[0,1], color='r', scale=5, label='PC1')\n",
    "plt.quiver(*origin_pt, vecs[1,0], vecs[1,1], color='g', scale=5, label='PC2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c743c59",
   "metadata": {},
   "source": [
    "# Task 2 : What happens if your X has nonlinearity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c238c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation\n",
    "x_21 = np.random.uniform(-10, 10, 1000)\n",
    "y_21 = x_21 * 2 + np.random.normal(0,1,1000) # add gaussian noise\n",
    "\n",
    "x_22 = np.random.uniform(-10, 10, 1000)\n",
    "y_22 = x_22 ** 2 + np.random.normal(0,1,1000) # add gaussian noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aadf1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "vals_21, vecs_21 = pca(data)\n",
    "vals_22, vecs_22 = pca(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "fig, (ax1,ax2) = plt.subplots(1,2)\n",
    "\n",
    "ax1.scatter(x_21, y_21, s=1)\n",
    "ax1.axis(\"equal\")\n",
    "# plt.xlim(-10, 10)\n",
    "# plt.ylim(-10, 10)\n",
    "ax1.set_xlabel(\"$x_1$\")\n",
    "ax1.set_ylabel(\"$x_2$\")\n",
    "ax1.quiver(*origin_pt, vecs_21[0,0], vecs_21[0,1], color='r', scale=5, label='PC1')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.scatter(x_22, y_22, s=1)\n",
    "ax2.axis(\"equal\")\n",
    "# plt.xlim(-10, 10)\n",
    "# plt.ylim(-10, 10)\n",
    "ax2.set_xlabel(\"$x_1$\")\n",
    "ax2.set_ylabel(\"$x_2$\")\n",
    "ax2.quiver(*origin_pt, vecs_22[0,0], vecs_22[0,1], color='r', scale=5, label='PC1')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afa002f",
   "metadata": {},
   "source": [
    "# Q3. AE & PCA\n",
    "A single layered AE with a linear activation function is in fact AE.\n",
    "\n",
    "1) What should we do to actually achieve this?\n",
    "Ans)\n",
    "\n",
    "two things:\n",
    "AutoEncoder has a linear activation function\n",
    "AutoEncoder has MSE (mean squared error) for loss function\n",
    "2) Using the answer you found in 1), implement AE for #1 & #2 cases & compare with PCA results. What are reconstruction MSEs? Does AE recover the PCs?\n",
    "Ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebaa518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cd7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAutoEncoder(nn.Module):\n",
    "    def __init__(self, in_features=2, enc_dim=64, latent_dim=2):\n",
    "        super(LinearAutoEncoder, self).__init__()\n",
    "        self.enc_layer = nn.Linear(in_features, latent_dim)\n",
    "        #self.act = nn.Tanh()\n",
    "        self.dec_layer = nn.Linear(latent_dim,in_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.enc_layer(x)\n",
    "        out = self.dec_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887b03b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.X = x\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.X[index]\n",
    "        return X\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe5f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(f_value)\n",
    "dataloader = DataLoader(dataset, batch_size=100)\n",
    "\n",
    "model = LinearAutoEncoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f76aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "from tqdm import tqdm\n",
    "for epoch in tqdm(range(30)):\n",
    "    for inputs in dataloader:\n",
    "        inputs = inputs.to(device).float()\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            output = model(inputs)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(inputs,output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.detach().cpu().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd57bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(losses)), losses)\n",
    "plt.title('linear encoder loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d72cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = sns.color_palette('Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf4454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with PCs\n",
    "data_norm = f_value\n",
    "val, vec = pca(f_value, method='eigen')\n",
    "enc_w = model.enc_layer.weight.detach().cpu().numpy()\n",
    "#print(vec)\n",
    "#print(enc_w)\n",
    "\n",
    "#plt.figure(figsize=(24,18))\n",
    "plt.scatter(data_norm[:,0], data_norm[:,1], alpha=0.5, color=color_palette[0], s=10)\n",
    "plt.arrow(0,0,vec[0][0],vec[0][1], width=0.01, head_width=0.2, color='red', label='pc1')\n",
    "plt.arrow(0,0,vec[1][0],vec[1][1], width=0.01, head_width=0.2, color='red', label='pc2')\n",
    "plt.arrow(0,0,enc_w[0,0],enc_w[0,1], width=0.01, head_width=0.2, color='blue', label='weight1')\n",
    "plt.arrow(0,0,enc_w[1,0],enc_w[1,1], width=0.01, head_width=0.2, color='blue', label='weight2')\n",
    "plt.title('visualize PCs and AE weights')\n",
    "plt.legend()\n",
    "#plt.savefig('Q3-2.png')\n",
    "\n",
    "plt.savefig('Q3-2-linear.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95147f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = sns.color_palette('Set2')\n",
    "data_norm = (f_value - np.mean(f_value)) / (np.std(f_value))\n",
    "val, vec = pca(data_norm, method='eigen')\n",
    "enc_w = model.enc_layer.weight.detach().cpu().numpy()\n",
    "grid = sns.JointGrid(data_norm[:,0], data_norm[:,1], palette='Set2')\n",
    "grid.plot_joint(plt.scatter, color=color_palette[0], alpha=0.5, s=10)\n",
    "plt.arrow(0,0,vec[0][0],vec[0][1], width=0.01, head_width=0.2, color='red', label='pc1')\n",
    "plt.arrow(0,0,vec[1][0],vec[1][1], width=0.01, head_width=0.2, color='red', label='pc2')\n",
    "plt.arrow(0,0,enc_w[0,0],enc_w[0,1], width=0.01, head_width=0.2, color='blue', label='weight1')\n",
    "plt.arrow(0,0,enc_w[1,0],enc_w[1,1], width=0.01, head_width=0.2, color='blue', label='weight2')\n",
    "#plt.title('f value and eigen vectors')\n",
    "grid.fig.suptitle('f value and eigen vectors')\n",
    "grid.fig.legend()\n",
    "plt.savefig('Q3-AE&PCA.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e558e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6148739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
